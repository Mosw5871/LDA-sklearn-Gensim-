{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54ab94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize  # 使用NLTK进行词汇分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160716fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/All_classed_Tweets1248546.csv'\n",
    "\n",
    "df = pd.read_csv(data_path, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8423aa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>hot_means</th>\n",
       "      <th>post_sentiment</th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>Emotion Range</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>resigndanielandrews bad china treat uighur wel...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9870</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese covid lockdown crisis nchinese buildin...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9864</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>know belt road know belt road guess bloody vil...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9840</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>explain beltandroad initiative deal devil evil...</td>\n",
       "      <td>-0.248537</td>\n",
       "      <td>-0.9837</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>explain beltandroad initiative deal devil evil...</td>\n",
       "      <td>-0.253004</td>\n",
       "      <td>-0.9837</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248541</th>\n",
       "      <td>1248541</td>\n",
       "      <td>china help afghan nation well life china alrea...</td>\n",
       "      <td>-0.252317</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248542</th>\n",
       "      <td>1248542</td>\n",
       "      <td>china help afghan nation well life china alrea...</td>\n",
       "      <td>-0.252317</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248543</th>\n",
       "      <td>1248543</td>\n",
       "      <td>nothing one belt one road way get degree junio...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248544</th>\n",
       "      <td>1248544</td>\n",
       "      <td>katyayan alessandra npakistan die death leave ...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248545</th>\n",
       "      <td>1248545</td>\n",
       "      <td>serious nbelt road initiative gladys liu call ...</td>\n",
       "      <td>-0.253004</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1248546 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                               text  \\\n",
       "0                 0  resigndanielandrews bad china treat uighur wel...   \n",
       "1                 1  chinese covid lockdown crisis nchinese buildin...   \n",
       "2                 2  know belt road know belt road guess bloody vil...   \n",
       "3                 3  explain beltandroad initiative deal devil evil...   \n",
       "4                 4  explain beltandroad initiative deal devil evil...   \n",
       "...             ...                                                ...   \n",
       "1248541     1248541  china help afghan nation well life china alrea...   \n",
       "1248542     1248542  china help afghan nation well life china alrea...   \n",
       "1248543     1248543  nothing one belt one road way get degree junio...   \n",
       "1248544     1248544  katyayan alessandra npakistan die death leave ...   \n",
       "1248545     1248545  serious nbelt road initiative gladys liu call ...   \n",
       "\n",
       "         hot_means  post_sentiment  Emotion Layer Emotion Range  class_means  \\\n",
       "0        -0.253691         -0.9870              0  -1.0 to -0.9    -0.928296   \n",
       "1        -0.253691         -0.9864              0  -1.0 to -0.9    -0.928296   \n",
       "2        -0.254035         -0.9840              0  -1.0 to -0.9    -0.928296   \n",
       "3        -0.248537         -0.9837              0  -1.0 to -0.9    -0.928296   \n",
       "4        -0.253004         -0.9837              0  -1.0 to -0.9    -0.928296   \n",
       "...            ...             ...            ...           ...          ...   \n",
       "1248541  -0.252317          0.9969             19    0.9 to 1.0     0.930934   \n",
       "1248542  -0.252317          0.9969             19    0.9 to 1.0     0.930934   \n",
       "1248543  -0.253691          0.9980             19    0.9 to 1.0     0.930934   \n",
       "1248544  -0.253691          0.9980             19    0.9 to 1.0     0.930934   \n",
       "1248545  -0.253004          0.9991             19    0.9 to 1.0     0.930934   \n",
       "\n",
       "         class_means.1  \n",
       "0            -0.169739  \n",
       "1            -0.169739  \n",
       "2            -0.169739  \n",
       "3            -0.169739  \n",
       "4            -0.169739  \n",
       "...                ...  \n",
       "1248541       0.162922  \n",
       "1248542       0.162922  \n",
       "1248543       0.162922  \n",
       "1248544       0.162922  \n",
       "1248545       0.162922  \n",
       "\n",
       "[1248546 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594a1869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba190223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>hot_means</th>\n",
       "      <th>post_sentiment</th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>Emotion Range</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>resigndanielandrews bad china treat uighur wel...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9870</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese covid lockdown crisis nchinese buildin...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9864</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>know belt road know belt road guess bloody vil...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9840</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>explain beltandroad initiative deal devil evil...</td>\n",
       "      <td>-0.248537</td>\n",
       "      <td>-0.9837</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>three chinese national die suicide bomb attack...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9836</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248540</th>\n",
       "      <td>1248540</td>\n",
       "      <td>china bad country nand china policy chinese on...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248541</th>\n",
       "      <td>1248541</td>\n",
       "      <td>china help afghan nation well life china alrea...</td>\n",
       "      <td>-0.252317</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248543</th>\n",
       "      <td>1248543</td>\n",
       "      <td>nothing one belt one road way get degree junio...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248544</th>\n",
       "      <td>1248544</td>\n",
       "      <td>katyayan alessandra npakistan die death leave ...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248545</th>\n",
       "      <td>1248545</td>\n",
       "      <td>serious nbelt road initiative gladys liu call ...</td>\n",
       "      <td>-0.253004</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331881 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                               text  \\\n",
       "0                 0  resigndanielandrews bad china treat uighur wel...   \n",
       "1                 1  chinese covid lockdown crisis nchinese buildin...   \n",
       "2                 2  know belt road know belt road guess bloody vil...   \n",
       "3                 3  explain beltandroad initiative deal devil evil...   \n",
       "12               12  three chinese national die suicide bomb attack...   \n",
       "...             ...                                                ...   \n",
       "1248540     1248540  china bad country nand china policy chinese on...   \n",
       "1248541     1248541  china help afghan nation well life china alrea...   \n",
       "1248543     1248543  nothing one belt one road way get degree junio...   \n",
       "1248544     1248544  katyayan alessandra npakistan die death leave ...   \n",
       "1248545     1248545  serious nbelt road initiative gladys liu call ...   \n",
       "\n",
       "         hot_means  post_sentiment  Emotion Layer Emotion Range  class_means  \\\n",
       "0        -0.253691         -0.9870              0  -1.0 to -0.9    -0.928296   \n",
       "1        -0.253691         -0.9864              0  -1.0 to -0.9    -0.928296   \n",
       "2        -0.254035         -0.9840              0  -1.0 to -0.9    -0.928296   \n",
       "3        -0.248537         -0.9837              0  -1.0 to -0.9    -0.928296   \n",
       "12       -0.254035         -0.9836              0  -1.0 to -0.9    -0.928296   \n",
       "...            ...             ...            ...           ...          ...   \n",
       "1248540  -0.254035          0.9964             19    0.9 to 1.0     0.930934   \n",
       "1248541  -0.252317          0.9969             19    0.9 to 1.0     0.930934   \n",
       "1248543  -0.253691          0.9980             19    0.9 to 1.0     0.930934   \n",
       "1248544  -0.253691          0.9980             19    0.9 to 1.0     0.930934   \n",
       "1248545  -0.253004          0.9991             19    0.9 to 1.0     0.930934   \n",
       "\n",
       "         class_means.1  \n",
       "0            -0.169739  \n",
       "1            -0.169739  \n",
       "2            -0.169739  \n",
       "3            -0.169739  \n",
       "12           -0.169739  \n",
       "...                ...  \n",
       "1248540       0.162922  \n",
       "1248541       0.162922  \n",
       "1248543       0.162922  \n",
       "1248544       0.162922  \n",
       "1248545       0.162922  \n",
       "\n",
       "[331881 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff4a63",
   "metadata": {},
   "source": [
    "# 下面开始词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34783d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有数据转换为字符串类型\n",
    "corpus = [str(sentence) for sentence in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c192d5dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T15:41:51.733370Z",
     "start_time": "2023-12-29T15:41:51.729216Z"
    }
   },
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef61b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用NLTK进行词汇分割\n",
    "tokenized_corpus = [word_tokenize(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7812b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T15:41:55.545871Z",
     "start_time": "2023-12-29T15:41:55.543893Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4889874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练Word2Vec模型\n",
    "model = Word2Vec(tokenized_corpus, vector_size=300, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d0856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型（可选）\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af9df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型（如果需要）\n",
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2265fc0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量 for 'xinjiang':\n",
      "[ 4.35736030e-01  7.62851954e-01 -6.90107569e-02 -4.16154861e-02\n",
      " -1.30970752e+00  1.06725156e-01  4.52926680e-02  1.95536524e-01\n",
      " -1.00060403e+00 -6.60187542e-01 -1.05257964e+00 -1.01040363e+00\n",
      "  8.09402585e-01  1.39764023e+00  6.58127293e-02 -9.39076185e-01\n",
      " -8.02247226e-01 -4.76894289e-01  3.13913971e-01  1.01920319e+00\n",
      "  3.16260338e-01 -1.54354823e+00 -3.36530775e-01  9.11720395e-01\n",
      " -5.04368424e-01 -4.84725803e-01 -9.37605083e-01  1.29498816e+00\n",
      "  2.17967343e+00 -3.60700399e-01  1.50325143e+00  1.13270915e+00\n",
      "  4.73999560e-01  2.16967440e+00  1.19049698e-01 -3.37016910e-01\n",
      " -9.37347054e-01  3.89312836e-03  4.22661811e-01  4.80155557e-01\n",
      " -4.74220246e-01 -4.17478323e-01  9.40312624e-01 -6.87745392e-01\n",
      " -9.07693863e-01 -4.57184136e-01  8.60631168e-01  3.45189035e-01\n",
      " -2.55526543e-01 -3.08912873e-01 -1.06212437e+00  1.96319029e-01\n",
      " -1.04435742e+00 -1.76426917e-01 -5.05139604e-02  6.30788386e-01\n",
      " -9.80269015e-01  1.05175197e+00 -7.02683687e-01 -2.86898315e-01\n",
      " -9.90716875e-01 -1.78551376e+00 -1.00300026e+00  1.60077542e-01\n",
      " -8.41081977e-01  4.37677577e-02 -8.26789618e-01 -1.17764309e-01\n",
      "  7.86900818e-01 -3.88567120e-01  8.39361608e-01  9.01492000e-01\n",
      " -6.00371599e-01  2.40357712e-01 -1.41178310e-01  6.42866567e-02\n",
      "  1.53754878e+00  1.41249686e-01  9.02146816e-01  6.60699308e-01\n",
      "  7.70922065e-01 -1.19577670e+00 -4.43543792e-01  2.27662679e-02\n",
      "  5.38602710e-01 -9.78034019e-01 -1.85887933e-01  1.11936212e+00\n",
      " -7.51702905e-01 -8.74607384e-01 -1.26721668e+00  5.57035923e-01\n",
      " -2.85793841e-01 -2.66979426e-01 -2.26327562e+00 -1.25621009e+00\n",
      " -6.76923156e-01  1.99242306e+00  6.66922688e-01 -5.25150120e-01\n",
      "  3.63852948e-01 -1.05204463e+00  1.80173479e-02  6.59306049e-02\n",
      " -3.65595818e-01  8.63756705e-03 -1.61701977e+00 -1.12354708e+00\n",
      "  1.38308692e+00  1.08505845e+00 -4.06813622e-01  5.28741002e-01\n",
      " -4.69808817e-01  3.70093048e-01  1.80530548e+00 -3.77555639e-01\n",
      "  6.60917461e-01  2.26967216e-01  7.40926743e-01 -1.33411109e-01\n",
      " -1.97944856e+00  7.22771883e-01 -8.46943676e-01 -6.36954606e-01\n",
      " -9.60839748e-01  4.10424650e-01 -2.08927083e+00  6.59983933e-01\n",
      " -6.99448645e-01  4.52415049e-01  5.51849008e-01  3.59288931e-01\n",
      " -1.38206974e-01 -1.12190580e+00  1.05269063e+00 -1.90277323e-01\n",
      " -2.61779249e-01  2.49436066e-01 -1.51162952e-01 -3.56612295e-01\n",
      " -1.00097694e-01 -5.04679739e-01 -9.14960504e-02  1.84814092e-02\n",
      "  9.37372565e-01 -1.08611859e-01 -1.93665609e-01  9.28692743e-02\n",
      " -6.22710943e-01  1.49362433e+00 -5.93823552e-01  8.41607273e-01\n",
      "  2.66061667e-02  2.49718651e-01  1.34983516e+00  3.92399877e-01\n",
      " -1.32035747e-01 -3.11661493e-02 -2.24387383e+00  3.63183320e-01\n",
      " -6.91346943e-01 -4.56171095e-01  1.09553111e+00  4.65728045e-01\n",
      "  8.05680752e-02 -2.59319806e+00 -1.30054593e+00 -1.73622298e+00\n",
      "  1.37912643e+00 -5.39908290e-01  7.52524972e-01 -4.86244351e-01\n",
      "  1.13282844e-01 -6.78653479e-01  9.46193457e-01 -1.63599980e+00\n",
      " -6.91697538e-01 -3.09647083e-01  5.26431739e-01  7.48666346e-01\n",
      " -4.19047615e-03 -9.55154449e-02  1.03581476e+00 -1.76782906e-03\n",
      "  2.05528080e-01  7.31852710e-01  2.41735786e-01  1.03583872e+00\n",
      " -8.17591727e-01  5.32770991e-01  5.84192276e-01  2.14560777e-01\n",
      "  8.06772187e-02  1.21823788e+00  1.64344698e-01 -4.03247587e-03\n",
      " -1.98290610e+00  1.61862421e+00  1.00367439e+00 -9.92539406e-01\n",
      " -3.72261822e-01  9.77912009e-01 -3.47231567e-01  1.60305321e+00\n",
      "  7.25139141e-01  5.03373802e-01  1.80543721e+00 -8.74889363e-03\n",
      " -9.37110841e-01 -8.41657817e-01  4.85661738e-02  1.68204963e+00\n",
      "  1.42571723e+00  6.95092678e-01 -6.36165142e-01 -1.89759001e-01\n",
      "  4.80267435e-01 -7.73360431e-02  8.32628727e-01 -4.41118926e-01\n",
      "  4.06149417e-01  3.68747145e-01  8.59547555e-01 -1.45049798e+00\n",
      " -4.66485739e-01 -2.25116849e-01 -1.51767671e-01  5.44633977e-02\n",
      " -1.14939606e+00 -6.69845799e-03 -5.65213323e-01  2.62804806e-01\n",
      " -2.89955497e-01  5.47078907e-01  1.73359171e-01  7.74567366e-01\n",
      "  1.22008480e-01  4.47063446e-01 -5.54804742e-01 -7.15241849e-01\n",
      "  3.25330168e-01 -1.27836716e+00  1.18760395e+00  7.16358602e-01\n",
      "  1.64377853e-01  4.67456371e-01 -1.59629238e+00  4.78921145e-01\n",
      " -5.90287328e-01  1.12805247e+00  1.13196731e+00 -8.75054225e-02\n",
      "  2.22523794e-01 -1.67727637e+00 -7.09144890e-01 -2.16067880e-01\n",
      " -1.18837452e+00  1.65547585e+00 -1.87197280e+00 -1.17972076e+00\n",
      " -2.02482477e-01  1.62955940e+00 -1.12664664e+00  6.42693162e-01\n",
      "  3.33522677e-01  1.02083266e+00  1.29159892e+00  7.05327153e-01\n",
      "  2.53083169e-01 -3.06428112e-02  3.99512388e-02 -1.27368569e+00\n",
      "  5.77694118e-01 -1.58662871e-01 -8.35521668e-02 -2.93567598e-01\n",
      "  1.35433602e+00  6.85902119e-01 -5.73308825e-01  1.22511804e+00\n",
      " -9.31649387e-01  1.87033260e+00  1.80394620e-01  1.71911907e+00\n",
      "  1.40820992e+00 -4.10924196e-01  1.52371898e-01  3.53795797e-01\n",
      "  1.25674927e+00 -1.17267001e+00  1.42574596e+00  3.20283510e-02\n",
      "  9.37031806e-01 -4.24517244e-01 -6.26375258e-01 -1.17778647e+00\n",
      " -2.00908512e-01  4.88063067e-01  1.26383352e+00  6.15367651e-01]\n"
     ]
    }
   ],
   "source": [
    "# 查找某个单词的词向量\n",
    "word_vector = model.wv['xinjiang']\n",
    "print(\"词向量 for 'xinjiang':\")\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a75833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与 'xinjiang' 最相似的单词:\n",
      "[('uyghur', 0.7542362213134766), ('uighur', 0.7456961870193481), ('uighurs', 0.724337637424469), ('uyghurs', 0.7201979160308838), ('tibet', 0.6856598854064941), ('uygur', 0.678943395614624), ('muslim', 0.6759054064750671), ('genocide', 0.6645978093147278), ('minority', 0.6530284285545349), ('separatism', 0.6333921551704407)]\n"
     ]
    }
   ],
   "source": [
    "# 查找与某个单词最相似的单词\n",
    "similar_words = model.wv.most_similar('xinjiang')\n",
    "print(\"与 'xinjiang' 最相似的单词:\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca25536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词向量加权平均，获取每一条推文的向量表示\n",
    "def get_post_vector(post, model):\n",
    "    # 分词帖子文本\n",
    "    words = post.split()  # 假设帖子已分词\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "\n",
    "    if len(word_vectors) > 0:\n",
    "        post_vector = np.mean(word_vectors, axis=0)  # 求均值\n",
    "        return post_vector\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # 如果帖子中没有词汇在模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3545f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wq/891pj93x7r99n97_2h5wxzzw0000gn/T/ipykernel_1692/2889800225.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['post_vector'] = df['text'].astype(str).apply(lambda x: get_post_vector(x, model))\n"
     ]
    }
   ],
   "source": [
    "# 假设你的DataFrame中有一个名为df的数据框，包含帖子文本在\"text\"列中\n",
    "df['post_vector'] = df['text'].astype(str).apply(lambda x: get_post_vector(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1640fb0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>hot_means</th>\n",
       "      <th>post_sentiment</th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>Emotion Range</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>post_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>resigndanielandrews bad china treat uighur wel...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9870</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.2543658, -0.07967505, 0.30819112, 0.3978624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese covid lockdown crisis nchinese buildin...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9864</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.28420353, -0.34272397, -0.12476715, -0.1113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>know belt road know belt road guess bloody vil...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9840</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.122677505, -0.07373391, 0.20550579, 0.37981...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>explain beltandroad initiative deal devil evil...</td>\n",
       "      <td>-0.248537</td>\n",
       "      <td>-0.9837</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.26954097, -0.10511088, 0.09689696, 0.471919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>three chinese national die suicide bomb attack...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9836</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.1213556, 0.007718099, 0.39149675, 0.3271283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248540</th>\n",
       "      <td>1248540</td>\n",
       "      <td>china bad country nand china policy chinese on...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[-0.01966426, -0.21998449, 0.53237987, 0.42408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248541</th>\n",
       "      <td>1248541</td>\n",
       "      <td>china help afghan nation well life china alrea...</td>\n",
       "      <td>-0.252317</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[-0.16921246, -0.41664734, 0.17753996, 0.28683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248543</th>\n",
       "      <td>1248543</td>\n",
       "      <td>nothing one belt one road way get degree junio...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[-0.025184812, -0.13662817, 0.3415161, 0.26124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248544</th>\n",
       "      <td>1248544</td>\n",
       "      <td>katyayan alessandra npakistan die death leave ...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.0936206, -0.0024508627, -0.005916714, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248545</th>\n",
       "      <td>1248545</td>\n",
       "      <td>serious nbelt road initiative gladys liu call ...</td>\n",
       "      <td>-0.253004</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.037158553, 0.07273631, 0.4617593, 0.4482960...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331881 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                               text  \\\n",
       "0                 0  resigndanielandrews bad china treat uighur wel...   \n",
       "1                 1  chinese covid lockdown crisis nchinese buildin...   \n",
       "2                 2  know belt road know belt road guess bloody vil...   \n",
       "3                 3  explain beltandroad initiative deal devil evil...   \n",
       "12               12  three chinese national die suicide bomb attack...   \n",
       "...             ...                                                ...   \n",
       "1248540     1248540  china bad country nand china policy chinese on...   \n",
       "1248541     1248541  china help afghan nation well life china alrea...   \n",
       "1248543     1248543  nothing one belt one road way get degree junio...   \n",
       "1248544     1248544  katyayan alessandra npakistan die death leave ...   \n",
       "1248545     1248545  serious nbelt road initiative gladys liu call ...   \n",
       "\n",
       "         hot_means  post_sentiment  Emotion Layer Emotion Range  class_means  \\\n",
       "0        -0.253691         -0.9870              0  -1.0 to -0.9    -0.928296   \n",
       "1        -0.253691         -0.9864              0  -1.0 to -0.9    -0.928296   \n",
       "2        -0.254035         -0.9840              0  -1.0 to -0.9    -0.928296   \n",
       "3        -0.248537         -0.9837              0  -1.0 to -0.9    -0.928296   \n",
       "12       -0.254035         -0.9836              0  -1.0 to -0.9    -0.928296   \n",
       "...            ...             ...            ...           ...          ...   \n",
       "1248540  -0.254035          0.9964             19    0.9 to 1.0     0.930934   \n",
       "1248541  -0.252317          0.9969             19    0.9 to 1.0     0.930934   \n",
       "1248543  -0.253691          0.9980             19    0.9 to 1.0     0.930934   \n",
       "1248544  -0.253691          0.9980             19    0.9 to 1.0     0.930934   \n",
       "1248545  -0.253004          0.9991             19    0.9 to 1.0     0.930934   \n",
       "\n",
       "         class_means.1                                        post_vector  \n",
       "0            -0.169739  [0.2543658, -0.07967505, 0.30819112, 0.3978624...  \n",
       "1            -0.169739  [0.28420353, -0.34272397, -0.12476715, -0.1113...  \n",
       "2            -0.169739  [0.122677505, -0.07373391, 0.20550579, 0.37981...  \n",
       "3            -0.169739  [0.26954097, -0.10511088, 0.09689696, 0.471919...  \n",
       "12           -0.169739  [0.1213556, 0.007718099, 0.39149675, 0.3271283...  \n",
       "...                ...                                                ...  \n",
       "1248540       0.162922  [-0.01966426, -0.21998449, 0.53237987, 0.42408...  \n",
       "1248541       0.162922  [-0.16921246, -0.41664734, 0.17753996, 0.28683...  \n",
       "1248543       0.162922  [-0.025184812, -0.13662817, 0.3415161, 0.26124...  \n",
       "1248544       0.162922  [0.0936206, -0.0024508627, -0.005916714, -0.02...  \n",
       "1248545       0.162922  [0.037158553, 0.07273631, 0.4617593, 0.4482960...  \n",
       "\n",
       "[331881 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e43aa2",
   "metadata": {},
   "source": [
    "## 计算每一个情感层的平均向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20e42f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Emotion Layer                                    avg_post_vector\n",
      "0              0  [0.11760008, -0.012402125, 0.06883323, 0.18810...\n",
      "1              1  [0.08207128, 0.01862477, 0.10427087, 0.1811638...\n",
      "2              2  [0.06760355, 0.044921156, 0.12549053, 0.187798...\n",
      "3              3  [0.07044438, 0.056576263, 0.14015777, 0.193998...\n",
      "4              4  [0.05443702, 0.08645568, 0.15405756, 0.2039342...\n",
      "5              5  [0.051918067, 0.09794764, 0.17074487, 0.201880...\n",
      "6              6  [0.020523963, 0.114622355, 0.18369444, 0.19349...\n",
      "7              7  [0.04576026, 0.120299615, 0.17240515, 0.219961...\n",
      "8              8  [0.06710039, 0.11539387, 0.1712008, 0.19498421...\n",
      "9              9  [-0.015748737, 0.20031922, 0.24642228, 0.23902...\n",
      "10            10  [0.05148924, 0.13149922, 0.1742623, 0.20957139...\n",
      "11            11  [0.033958852, 0.15325545, 0.18930002, 0.206858...\n",
      "12            12  [0.04171288, 0.17342085, 0.20434242, 0.2056923...\n",
      "13            13  [0.00036949065, 0.18357617, 0.24112386, 0.2211...\n",
      "14            14  [0.012569518, 0.18865114, 0.24133429, 0.233439...\n",
      "15            15  [0.024460258, 0.16273473, 0.21841373, 0.209432...\n",
      "16            16  [0.024241004, 0.14219262, 0.2338202, 0.2115629...\n",
      "17            17  [0.035018533, 0.135265, 0.2168061, 0.20091766,...\n",
      "18            18  [0.04702486, 0.11094685, 0.20541945, 0.1919958...\n",
      "19            19  [0.049404424, 0.07209667, 0.2152316, 0.1950995...\n"
     ]
    }
   ],
   "source": [
    "# 创建一个新数据框emotion_vectors，用于存储每个情感层的平均向量\n",
    "\n",
    "emotion_vectors = pd.DataFrame(columns=[\"Emotion Layer\", \"avg_post_vector\"])\n",
    "\n",
    "# 遍历每个情感层\n",
    "for sentiment_layer, group in df.groupby(\"Emotion Layer\"):\n",
    "    # 计算每个情感层的平均帖子向量\n",
    "    avg_vector = group[\"post_vector\"].mean()\n",
    "    \n",
    "    # 添加到结果数据框\n",
    "    emotion_vectors = pd.concat([emotion_vectors, pd.DataFrame({\"Emotion Layer\": [sentiment_layer], \"avg_post_vector\": [avg_vector]})], ignore_index=True)\n",
    "\n",
    "# 输出每个情感层的平均帖子向量\n",
    "print(emotion_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c15e16",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 将每一情感层的平均向量合并回原数据框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11140034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 merge 函数将 emotion_vectors 合并回 df，基于 \"Emotion Layer\" 列合并\n",
    "\n",
    "merged_df = df.merge(emotion_vectors, on = 'Emotion Layer', how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d97a48c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>hot_means</th>\n",
       "      <th>post_sentiment</th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>Emotion Range</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>post_vector</th>\n",
       "      <th>avg_post_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>resigndanielandrews bad china treat uighur wel...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9870</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.2543658, -0.07967505, 0.30819112, 0.3978624...</td>\n",
       "      <td>[0.11760008, -0.012402125, 0.06883323, 0.18810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese covid lockdown crisis nchinese buildin...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>-0.9864</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.28420353, -0.34272397, -0.12476715, -0.1113...</td>\n",
       "      <td>[0.11760008, -0.012402125, 0.06883323, 0.18810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>know belt road know belt road guess bloody vil...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9840</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.122677505, -0.07373391, 0.20550579, 0.37981...</td>\n",
       "      <td>[0.11760008, -0.012402125, 0.06883323, 0.18810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>explain beltandroad initiative deal devil evil...</td>\n",
       "      <td>-0.248537</td>\n",
       "      <td>-0.9837</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.26954097, -0.10511088, 0.09689696, 0.471919...</td>\n",
       "      <td>[0.11760008, -0.012402125, 0.06883323, 0.18810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>three chinese national die suicide bomb attack...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>-0.9836</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0 to -0.9</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.1213556, 0.007718099, 0.39149675, 0.3271283...</td>\n",
       "      <td>[0.11760008, -0.012402125, 0.06883323, 0.18810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331876</th>\n",
       "      <td>1248540</td>\n",
       "      <td>china bad country nand china policy chinese on...</td>\n",
       "      <td>-0.254035</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[-0.01966426, -0.21998449, 0.53237987, 0.42408...</td>\n",
       "      <td>[0.049404424, 0.07209667, 0.2152316, 0.1950995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331877</th>\n",
       "      <td>1248541</td>\n",
       "      <td>china help afghan nation well life china alrea...</td>\n",
       "      <td>-0.252317</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[-0.16921246, -0.41664734, 0.17753996, 0.28683...</td>\n",
       "      <td>[0.049404424, 0.07209667, 0.2152316, 0.1950995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331878</th>\n",
       "      <td>1248543</td>\n",
       "      <td>nothing one belt one road way get degree junio...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[-0.025184812, -0.13662817, 0.3415161, 0.26124...</td>\n",
       "      <td>[0.049404424, 0.07209667, 0.2152316, 0.1950995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331879</th>\n",
       "      <td>1248544</td>\n",
       "      <td>katyayan alessandra npakistan die death leave ...</td>\n",
       "      <td>-0.253691</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.0936206, -0.0024508627, -0.005916714, -0.02...</td>\n",
       "      <td>[0.049404424, 0.07209667, 0.2152316, 0.1950995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331880</th>\n",
       "      <td>1248545</td>\n",
       "      <td>serious nbelt road initiative gladys liu call ...</td>\n",
       "      <td>-0.253004</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9 to 1.0</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.037158553, 0.07273631, 0.4617593, 0.4482960...</td>\n",
       "      <td>[0.049404424, 0.07209667, 0.2152316, 0.1950995...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331881 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  resigndanielandrews bad china treat uighur wel...   \n",
       "1                1  chinese covid lockdown crisis nchinese buildin...   \n",
       "2                2  know belt road know belt road guess bloody vil...   \n",
       "3                3  explain beltandroad initiative deal devil evil...   \n",
       "4               12  three chinese national die suicide bomb attack...   \n",
       "...            ...                                                ...   \n",
       "331876     1248540  china bad country nand china policy chinese on...   \n",
       "331877     1248541  china help afghan nation well life china alrea...   \n",
       "331878     1248543  nothing one belt one road way get degree junio...   \n",
       "331879     1248544  katyayan alessandra npakistan die death leave ...   \n",
       "331880     1248545  serious nbelt road initiative gladys liu call ...   \n",
       "\n",
       "        hot_means  post_sentiment Emotion Layer Emotion Range  class_means  \\\n",
       "0       -0.253691         -0.9870             0  -1.0 to -0.9    -0.928296   \n",
       "1       -0.253691         -0.9864             0  -1.0 to -0.9    -0.928296   \n",
       "2       -0.254035         -0.9840             0  -1.0 to -0.9    -0.928296   \n",
       "3       -0.248537         -0.9837             0  -1.0 to -0.9    -0.928296   \n",
       "4       -0.254035         -0.9836             0  -1.0 to -0.9    -0.928296   \n",
       "...           ...             ...           ...           ...          ...   \n",
       "331876  -0.254035          0.9964            19    0.9 to 1.0     0.930934   \n",
       "331877  -0.252317          0.9969            19    0.9 to 1.0     0.930934   \n",
       "331878  -0.253691          0.9980            19    0.9 to 1.0     0.930934   \n",
       "331879  -0.253691          0.9980            19    0.9 to 1.0     0.930934   \n",
       "331880  -0.253004          0.9991            19    0.9 to 1.0     0.930934   \n",
       "\n",
       "        class_means.1                                        post_vector  \\\n",
       "0           -0.169739  [0.2543658, -0.07967505, 0.30819112, 0.3978624...   \n",
       "1           -0.169739  [0.28420353, -0.34272397, -0.12476715, -0.1113...   \n",
       "2           -0.169739  [0.122677505, -0.07373391, 0.20550579, 0.37981...   \n",
       "3           -0.169739  [0.26954097, -0.10511088, 0.09689696, 0.471919...   \n",
       "4           -0.169739  [0.1213556, 0.007718099, 0.39149675, 0.3271283...   \n",
       "...               ...                                                ...   \n",
       "331876       0.162922  [-0.01966426, -0.21998449, 0.53237987, 0.42408...   \n",
       "331877       0.162922  [-0.16921246, -0.41664734, 0.17753996, 0.28683...   \n",
       "331878       0.162922  [-0.025184812, -0.13662817, 0.3415161, 0.26124...   \n",
       "331879       0.162922  [0.0936206, -0.0024508627, -0.005916714, -0.02...   \n",
       "331880       0.162922  [0.037158553, 0.07273631, 0.4617593, 0.4482960...   \n",
       "\n",
       "                                          avg_post_vector  \n",
       "0       [0.11760008, -0.012402125, 0.06883323, 0.18810...  \n",
       "1       [0.11760008, -0.012402125, 0.06883323, 0.18810...  \n",
       "2       [0.11760008, -0.012402125, 0.06883323, 0.18810...  \n",
       "3       [0.11760008, -0.012402125, 0.06883323, 0.18810...  \n",
       "4       [0.11760008, -0.012402125, 0.06883323, 0.18810...  \n",
       "...                                                   ...  \n",
       "331876  [0.049404424, 0.07209667, 0.2152316, 0.1950995...  \n",
       "331877  [0.049404424, 0.07209667, 0.2152316, 0.1950995...  \n",
       "331878  [0.049404424, 0.07209667, 0.2152316, 0.1950995...  \n",
       "331879  [0.049404424, 0.07209667, 0.2152316, 0.1950995...  \n",
       "331880  [0.049404424, 0.07209667, 0.2152316, 0.1950995...  \n",
       "\n",
       "[331881 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b509e",
   "metadata": {},
   "source": [
    "# 计算两两情感层之间的“情感差值”，并计算相应的两情感层文本相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11b65c",
   "metadata": {},
   "source": [
    "这里的两情感层的情感差值，代表了情感极性的分化程度，差值越大，代表两层情感的两极化程度越高。文本相似度随着两极化程度的提高而逐渐下降。\n",
    "\n",
    "由于一层情感取的是每一条帖子的均值，因此结论也适用于个体（平均人，代表了每一个个体的普遍状态状态）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a2f338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a8591d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每一层的帖子的情感、转评赞的均值，单独提取出来\n",
    "result = merged_df.groupby('Emotion Layer').agg({'class_means': 'mean',\n",
    "                                                 'class_means.1': 'mean',\n",
    "                                                 'avg_post_vector': 'mean', \n",
    "                                                 'text': 'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed85117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.11759956, -0.01240221, 0.06883255, 0.188099...</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>[0.08206962, 0.018623926, 0.10427251, 0.181156...</td>\n",
       "      <td>4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>[0.06759872, 0.044921823, 0.12548852, 0.187796...</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>[0.07044125, 0.056578968, 0.14015035, 0.193981...</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>[0.054441523, 0.08644522, 0.15405329, 0.203952...</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>[0.05191691, 0.09795757, 0.1707494, 0.20189716...</td>\n",
       "      <td>10187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>[0.02052315, 0.11462396, 0.18370864, 0.1934834...</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>[0.04575353, 0.12028619, 0.1723895, 0.21996947...</td>\n",
       "      <td>11067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>[0.067101896, 0.115399264, 0.17119475, 0.19498...</td>\n",
       "      <td>6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>[-0.015747102, 0.20054203, 0.24620117, 0.23879...</td>\n",
       "      <td>120919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>[0.05148582, 0.13148741, 0.17426367, 0.2095842...</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.176417</td>\n",
       "      <td>[0.033962816, 0.15324391, 0.18930298, 0.206876...</td>\n",
       "      <td>8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>-0.111372</td>\n",
       "      <td>[0.04170527, 0.17339887, 0.20434564, 0.2057485...</td>\n",
       "      <td>19535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>[0.00036953914, 0.18359077, 0.24117234, 0.2211...</td>\n",
       "      <td>21751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.080733</td>\n",
       "      <td>[0.012572618, 0.18861452, 0.24131083, 0.233405...</td>\n",
       "      <td>31101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>[0.024465693, 0.16275266, 0.2184426, 0.2094585...</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>-0.145374</td>\n",
       "      <td>[0.024239006, 0.14219417, 0.23383643, 0.211597...</td>\n",
       "      <td>16013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>[0.035012137, 0.1352557, 0.21679793, 0.2009265...</td>\n",
       "      <td>13152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>[0.047027096, 0.110957816, 0.20543592, 0.19200...</td>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.049405783, 0.07209749, 0.21523431, 0.195098...</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion Layer  class_means  class_means.1  \\\n",
       "0               0    -0.928296      -0.169739   \n",
       "1               1    -0.845232      -0.127592   \n",
       "2               2    -0.749895      -0.110690   \n",
       "3               3    -0.646874      -0.138797   \n",
       "4               4    -0.551272       0.059986   \n",
       "5               5    -0.442627      -0.021977   \n",
       "6               6    -0.349682      -0.165579   \n",
       "7               7    -0.252877      -0.073312   \n",
       "8               8    -0.140920      -0.064764   \n",
       "9               9    -0.002524       0.021858   \n",
       "10             10     0.056094      -0.066174   \n",
       "11             11     0.139707      -0.176417   \n",
       "12             12     0.257558      -0.111372   \n",
       "13             13     0.352665      -0.093678   \n",
       "14             14     0.441582       0.080733   \n",
       "15             15     0.554503      -0.198971   \n",
       "16             16     0.647155      -0.145374   \n",
       "17             17     0.745005       0.221816   \n",
       "18             18     0.840652       0.932850   \n",
       "19             19     0.930934       0.162922   \n",
       "\n",
       "                                      avg_post_vector    text  \n",
       "0   [0.11759956, -0.01240221, 0.06883255, 0.188099...    1491  \n",
       "1   [0.08206962, 0.018623926, 0.10427251, 0.181156...    4639  \n",
       "2   [0.06759872, 0.044921823, 0.12548852, 0.187796...    6246  \n",
       "3   [0.07044125, 0.056578968, 0.14015035, 0.193981...    6614  \n",
       "4   [0.054441523, 0.08644522, 0.15405329, 0.203952...    9290  \n",
       "5   [0.05191691, 0.09795757, 0.1707494, 0.20189716...   10187  \n",
       "6   [0.02052315, 0.11462396, 0.18370864, 0.1934834...    9581  \n",
       "7   [0.04575353, 0.12028619, 0.1723895, 0.21996947...   11067  \n",
       "8   [0.067101896, 0.115399264, 0.17119475, 0.19498...    6975  \n",
       "9   [-0.015747102, 0.20054203, 0.24620117, 0.23879...  120919  \n",
       "10  [0.05148582, 0.13148741, 0.17426367, 0.2095842...    6696  \n",
       "11  [0.033962816, 0.15324391, 0.18930298, 0.206876...    8824  \n",
       "12  [0.04170527, 0.17339887, 0.20434564, 0.2057485...   19535  \n",
       "13  [0.00036953914, 0.18359077, 0.24117234, 0.2211...   21751  \n",
       "14  [0.012572618, 0.18861452, 0.24131083, 0.233405...   31101  \n",
       "15  [0.024465693, 0.16275266, 0.2184426, 0.2094585...   16965  \n",
       "16  [0.024239006, 0.14219417, 0.23383643, 0.211597...   16013  \n",
       "17  [0.035012137, 0.1352557, 0.21679793, 0.2009265...   13152  \n",
       "18  [0.047027096, 0.110957816, 0.20543592, 0.19200...    8590  \n",
       "19  [0.049405783, 0.07209749, 0.21523431, 0.195098...    2244  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8288913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的列表，用于存储结果的字典\n",
    "result_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f683bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有可能的情感层组合\n",
    "emotion_layers = result[\"class_means\"].tolist()\n",
    "combinations_layers = list(combinations(emotion_layers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "237fd184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.9282955333469304, -0.8452324821246169),\n",
       " (-0.9282955333469304, -0.7498948070230321),\n",
       " (-0.9282955333469304, -0.6468743565963367),\n",
       " (-0.9282955333469304, -0.5512723763506517),\n",
       " (-0.9282955333469304, -0.4426270051778038),\n",
       " (-0.9282955333469304, -0.3496819526061169),\n",
       " (-0.9282955333469304, -0.2528772433689287),\n",
       " (-0.9282955333469304, -0.1409204465292171),\n",
       " (-0.9282955333469304, -0.0025239789006360996),\n",
       " (-0.9282955333469304, 0.05609369853454289),\n",
       " (-0.9282955333469304, 0.1397067765844804),\n",
       " (-0.9282955333469304, 0.2575582423485321),\n",
       " (-0.9282955333469304, 0.3526654761904761),\n",
       " (-0.9282955333469304, 0.4415820899187819),\n",
       " (-0.9282955333469304, 0.5545028196168214),\n",
       " (-0.9282955333469304, 0.6471546208649698),\n",
       " (-0.9282955333469304, 0.7450054143855014),\n",
       " (-0.9282955333469304, 0.8406521440271439),\n",
       " (-0.9282955333469304, 0.9309343715511957),\n",
       " (-0.8452324821246169, -0.7498948070230321),\n",
       " (-0.8452324821246169, -0.6468743565963367),\n",
       " (-0.8452324821246169, -0.5512723763506517),\n",
       " (-0.8452324821246169, -0.4426270051778038),\n",
       " (-0.8452324821246169, -0.3496819526061169),\n",
       " (-0.8452324821246169, -0.2528772433689287),\n",
       " (-0.8452324821246169, -0.1409204465292171),\n",
       " (-0.8452324821246169, -0.0025239789006360996),\n",
       " (-0.8452324821246169, 0.05609369853454289),\n",
       " (-0.8452324821246169, 0.1397067765844804),\n",
       " (-0.8452324821246169, 0.2575582423485321),\n",
       " (-0.8452324821246169, 0.3526654761904761),\n",
       " (-0.8452324821246169, 0.4415820899187819),\n",
       " (-0.8452324821246169, 0.5545028196168214),\n",
       " (-0.8452324821246169, 0.6471546208649698),\n",
       " (-0.8452324821246169, 0.7450054143855014),\n",
       " (-0.8452324821246169, 0.8406521440271439),\n",
       " (-0.8452324821246169, 0.9309343715511957),\n",
       " (-0.7498948070230321, -0.6468743565963367),\n",
       " (-0.7498948070230321, -0.5512723763506517),\n",
       " (-0.7498948070230321, -0.4426270051778038),\n",
       " (-0.7498948070230321, -0.3496819526061169),\n",
       " (-0.7498948070230321, -0.2528772433689287),\n",
       " (-0.7498948070230321, -0.1409204465292171),\n",
       " (-0.7498948070230321, -0.0025239789006360996),\n",
       " (-0.7498948070230321, 0.05609369853454289),\n",
       " (-0.7498948070230321, 0.1397067765844804),\n",
       " (-0.7498948070230321, 0.2575582423485321),\n",
       " (-0.7498948070230321, 0.3526654761904761),\n",
       " (-0.7498948070230321, 0.4415820899187819),\n",
       " (-0.7498948070230321, 0.5545028196168214),\n",
       " (-0.7498948070230321, 0.6471546208649698),\n",
       " (-0.7498948070230321, 0.7450054143855014),\n",
       " (-0.7498948070230321, 0.8406521440271439),\n",
       " (-0.7498948070230321, 0.9309343715511957),\n",
       " (-0.6468743565963367, -0.5512723763506517),\n",
       " (-0.6468743565963367, -0.4426270051778038),\n",
       " (-0.6468743565963367, -0.3496819526061169),\n",
       " (-0.6468743565963367, -0.2528772433689287),\n",
       " (-0.6468743565963367, -0.1409204465292171),\n",
       " (-0.6468743565963367, -0.0025239789006360996),\n",
       " (-0.6468743565963367, 0.05609369853454289),\n",
       " (-0.6468743565963367, 0.1397067765844804),\n",
       " (-0.6468743565963367, 0.2575582423485321),\n",
       " (-0.6468743565963367, 0.3526654761904761),\n",
       " (-0.6468743565963367, 0.4415820899187819),\n",
       " (-0.6468743565963367, 0.5545028196168214),\n",
       " (-0.6468743565963367, 0.6471546208649698),\n",
       " (-0.6468743565963367, 0.7450054143855014),\n",
       " (-0.6468743565963367, 0.8406521440271439),\n",
       " (-0.6468743565963367, 0.9309343715511957),\n",
       " (-0.5512723763506517, -0.4426270051778038),\n",
       " (-0.5512723763506517, -0.3496819526061169),\n",
       " (-0.5512723763506517, -0.2528772433689287),\n",
       " (-0.5512723763506517, -0.1409204465292171),\n",
       " (-0.5512723763506517, -0.0025239789006360996),\n",
       " (-0.5512723763506517, 0.05609369853454289),\n",
       " (-0.5512723763506517, 0.1397067765844804),\n",
       " (-0.5512723763506517, 0.2575582423485321),\n",
       " (-0.5512723763506517, 0.3526654761904761),\n",
       " (-0.5512723763506517, 0.4415820899187819),\n",
       " (-0.5512723763506517, 0.5545028196168214),\n",
       " (-0.5512723763506517, 0.6471546208649698),\n",
       " (-0.5512723763506517, 0.7450054143855014),\n",
       " (-0.5512723763506517, 0.8406521440271439),\n",
       " (-0.5512723763506517, 0.9309343715511957),\n",
       " (-0.4426270051778038, -0.3496819526061169),\n",
       " (-0.4426270051778038, -0.2528772433689287),\n",
       " (-0.4426270051778038, -0.1409204465292171),\n",
       " (-0.4426270051778038, -0.0025239789006360996),\n",
       " (-0.4426270051778038, 0.05609369853454289),\n",
       " (-0.4426270051778038, 0.1397067765844804),\n",
       " (-0.4426270051778038, 0.2575582423485321),\n",
       " (-0.4426270051778038, 0.3526654761904761),\n",
       " (-0.4426270051778038, 0.4415820899187819),\n",
       " (-0.4426270051778038, 0.5545028196168214),\n",
       " (-0.4426270051778038, 0.6471546208649698),\n",
       " (-0.4426270051778038, 0.7450054143855014),\n",
       " (-0.4426270051778038, 0.8406521440271439),\n",
       " (-0.4426270051778038, 0.9309343715511957),\n",
       " (-0.3496819526061169, -0.2528772433689287),\n",
       " (-0.3496819526061169, -0.1409204465292171),\n",
       " (-0.3496819526061169, -0.0025239789006360996),\n",
       " (-0.3496819526061169, 0.05609369853454289),\n",
       " (-0.3496819526061169, 0.1397067765844804),\n",
       " (-0.3496819526061169, 0.2575582423485321),\n",
       " (-0.3496819526061169, 0.3526654761904761),\n",
       " (-0.3496819526061169, 0.4415820899187819),\n",
       " (-0.3496819526061169, 0.5545028196168214),\n",
       " (-0.3496819526061169, 0.6471546208649698),\n",
       " (-0.3496819526061169, 0.7450054143855014),\n",
       " (-0.3496819526061169, 0.8406521440271439),\n",
       " (-0.3496819526061169, 0.9309343715511957),\n",
       " (-0.2528772433689287, -0.1409204465292171),\n",
       " (-0.2528772433689287, -0.0025239789006360996),\n",
       " (-0.2528772433689287, 0.05609369853454289),\n",
       " (-0.2528772433689287, 0.1397067765844804),\n",
       " (-0.2528772433689287, 0.2575582423485321),\n",
       " (-0.2528772433689287, 0.3526654761904761),\n",
       " (-0.2528772433689287, 0.4415820899187819),\n",
       " (-0.2528772433689287, 0.5545028196168214),\n",
       " (-0.2528772433689287, 0.6471546208649698),\n",
       " (-0.2528772433689287, 0.7450054143855014),\n",
       " (-0.2528772433689287, 0.8406521440271439),\n",
       " (-0.2528772433689287, 0.9309343715511957),\n",
       " (-0.1409204465292171, -0.0025239789006360996),\n",
       " (-0.1409204465292171, 0.05609369853454289),\n",
       " (-0.1409204465292171, 0.1397067765844804),\n",
       " (-0.1409204465292171, 0.2575582423485321),\n",
       " (-0.1409204465292171, 0.3526654761904761),\n",
       " (-0.1409204465292171, 0.4415820899187819),\n",
       " (-0.1409204465292171, 0.5545028196168214),\n",
       " (-0.1409204465292171, 0.6471546208649698),\n",
       " (-0.1409204465292171, 0.7450054143855014),\n",
       " (-0.1409204465292171, 0.8406521440271439),\n",
       " (-0.1409204465292171, 0.9309343715511957),\n",
       " (-0.0025239789006360996, 0.05609369853454289),\n",
       " (-0.0025239789006360996, 0.1397067765844804),\n",
       " (-0.0025239789006360996, 0.2575582423485321),\n",
       " (-0.0025239789006360996, 0.3526654761904761),\n",
       " (-0.0025239789006360996, 0.4415820899187819),\n",
       " (-0.0025239789006360996, 0.5545028196168214),\n",
       " (-0.0025239789006360996, 0.6471546208649698),\n",
       " (-0.0025239789006360996, 0.7450054143855014),\n",
       " (-0.0025239789006360996, 0.8406521440271439),\n",
       " (-0.0025239789006360996, 0.9309343715511957),\n",
       " (0.05609369853454289, 0.1397067765844804),\n",
       " (0.05609369853454289, 0.2575582423485321),\n",
       " (0.05609369853454289, 0.3526654761904761),\n",
       " (0.05609369853454289, 0.4415820899187819),\n",
       " (0.05609369853454289, 0.5545028196168214),\n",
       " (0.05609369853454289, 0.6471546208649698),\n",
       " (0.05609369853454289, 0.7450054143855014),\n",
       " (0.05609369853454289, 0.8406521440271439),\n",
       " (0.05609369853454289, 0.9309343715511957),\n",
       " (0.1397067765844804, 0.2575582423485321),\n",
       " (0.1397067765844804, 0.3526654761904761),\n",
       " (0.1397067765844804, 0.4415820899187819),\n",
       " (0.1397067765844804, 0.5545028196168214),\n",
       " (0.1397067765844804, 0.6471546208649698),\n",
       " (0.1397067765844804, 0.7450054143855014),\n",
       " (0.1397067765844804, 0.8406521440271439),\n",
       " (0.1397067765844804, 0.9309343715511957),\n",
       " (0.2575582423485321, 0.3526654761904761),\n",
       " (0.2575582423485321, 0.4415820899187819),\n",
       " (0.2575582423485321, 0.5545028196168214),\n",
       " (0.2575582423485321, 0.6471546208649698),\n",
       " (0.2575582423485321, 0.7450054143855014),\n",
       " (0.2575582423485321, 0.8406521440271439),\n",
       " (0.2575582423485321, 0.9309343715511957),\n",
       " (0.3526654761904761, 0.4415820899187819),\n",
       " (0.3526654761904761, 0.5545028196168214),\n",
       " (0.3526654761904761, 0.6471546208649698),\n",
       " (0.3526654761904761, 0.7450054143855014),\n",
       " (0.3526654761904761, 0.8406521440271439),\n",
       " (0.3526654761904761, 0.9309343715511957),\n",
       " (0.4415820899187819, 0.5545028196168214),\n",
       " (0.4415820899187819, 0.6471546208649698),\n",
       " (0.4415820899187819, 0.7450054143855014),\n",
       " (0.4415820899187819, 0.8406521440271439),\n",
       " (0.4415820899187819, 0.9309343715511957),\n",
       " (0.5545028196168214, 0.6471546208649698),\n",
       " (0.5545028196168214, 0.7450054143855014),\n",
       " (0.5545028196168214, 0.8406521440271439),\n",
       " (0.5545028196168214, 0.9309343715511957),\n",
       " (0.6471546208649698, 0.7450054143855014),\n",
       " (0.6471546208649698, 0.8406521440271439),\n",
       " (0.6471546208649698, 0.9309343715511957),\n",
       " (0.7450054143855014, 0.8406521440271439),\n",
       " (0.7450054143855014, 0.9309343715511957),\n",
       " (0.8406521440271439, 0.9309343715511957)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d56698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4cac1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个情感层组合\n",
    "for layer1, layer2 in combinations_layers:\n",
    "    # 获取对应的帖子文本向量\n",
    "    vector_layer1 = result[result['class_means'] == layer1]['avg_post_vector'].values[0]\n",
    "    vector_layer2 = result[result['class_means'] == layer2]['avg_post_vector'].values[0]\n",
    "\n",
    "    # 计算情感得分差值\n",
    "    sentiment_difference = layer2 - layer1\n",
    "\n",
    "    # 计算文本相似度\n",
    "    similarity = cosine_similarity([vector_layer1], [vector_layer2])[0][0]\n",
    "\n",
    "    # 将结果添加到结果数据列表中\n",
    "    result_data.append({\n",
    "        \"emotion_layer1\": layer1,\n",
    "        \"emotion_layer2\": layer2,\n",
    "        \"sentiment_difference\": sentiment_difference,\n",
    "        \"text_similarity\": similarity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9df81252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_layer1</th>\n",
       "      <th>emotion_layer2</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>text_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>0.083063</td>\n",
       "      <td>0.995212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>0.178401</td>\n",
       "      <td>0.988209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.982336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>0.377023</td>\n",
       "      <td>0.978165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>0.485669</td>\n",
       "      <td>0.964328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.193498</td>\n",
       "      <td>0.996553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.283780</td>\n",
       "      <td>0.987841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.095647</td>\n",
       "      <td>0.998787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.185929</td>\n",
       "      <td>0.991773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.090282</td>\n",
       "      <td>0.996077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion_layer1  emotion_layer2  sentiment_difference  text_similarity\n",
       "0         -0.928296       -0.845232              0.083063         0.995212\n",
       "1         -0.928296       -0.749895              0.178401         0.988209\n",
       "2         -0.928296       -0.646874              0.281421         0.982336\n",
       "3         -0.928296       -0.551272              0.377023         0.978165\n",
       "4         -0.928296       -0.442627              0.485669         0.964328\n",
       "..              ...             ...                   ...              ...\n",
       "185        0.647155        0.840652              0.193498         0.996553\n",
       "186        0.647155        0.930934              0.283780         0.987841\n",
       "187        0.745005        0.840652              0.095647         0.998787\n",
       "188        0.745005        0.930934              0.185929         0.991773\n",
       "189        0.840652        0.930934              0.090282         0.996077\n",
       "\n",
       "[190 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pd.DataFrame 将结果数据转换为 DataFrame\n",
    "result_df = pd.DataFrame(result_data)\n",
    "\n",
    "# 打印或使用 result_df\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68f510c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/result_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cbbb7b",
   "metadata": {},
   "source": [
    "# 根据情感强度，分析积极与消极情感各自的强度与文本相似度的关联"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb10017",
   "metadata": {},
   "source": [
    "## 消极情感的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6408948c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.11759956, -0.01240221, 0.06883255, 0.188099...</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>[0.08206962, 0.018623926, 0.10427251, 0.181156...</td>\n",
       "      <td>4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>[0.06759872, 0.044921823, 0.12548852, 0.187796...</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>[0.07044125, 0.056578968, 0.14015035, 0.193981...</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>[0.054441523, 0.08644522, 0.15405329, 0.203952...</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>[0.05191691, 0.09795757, 0.1707494, 0.20189716...</td>\n",
       "      <td>10187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>[0.02052315, 0.11462396, 0.18370864, 0.1934834...</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>[0.04575353, 0.12028619, 0.1723895, 0.21996947...</td>\n",
       "      <td>11067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>[0.067101896, 0.115399264, 0.17119475, 0.19498...</td>\n",
       "      <td>6975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion Layer  class_means  class_means.1  \\\n",
       "0              0    -0.928296      -0.169739   \n",
       "1              1    -0.845232      -0.127592   \n",
       "2              2    -0.749895      -0.110690   \n",
       "3              3    -0.646874      -0.138797   \n",
       "4              4    -0.551272       0.059986   \n",
       "5              5    -0.442627      -0.021977   \n",
       "6              6    -0.349682      -0.165579   \n",
       "7              7    -0.252877      -0.073312   \n",
       "8              8    -0.140920      -0.064764   \n",
       "\n",
       "                                     avg_post_vector   text  \n",
       "0  [0.11759956, -0.01240221, 0.06883255, 0.188099...   1491  \n",
       "1  [0.08206962, 0.018623926, 0.10427251, 0.181156...   4639  \n",
       "2  [0.06759872, 0.044921823, 0.12548852, 0.187796...   6246  \n",
       "3  [0.07044125, 0.056578968, 0.14015035, 0.193981...   6614  \n",
       "4  [0.054441523, 0.08644522, 0.15405329, 0.203952...   9290  \n",
       "5  [0.05191691, 0.09795757, 0.1707494, 0.20189716...  10187  \n",
       "6  [0.02052315, 0.11462396, 0.18370864, 0.1934834...   9581  \n",
       "7  [0.04575353, 0.12028619, 0.1723895, 0.21996947...  11067  \n",
       "8  [0.067101896, 0.115399264, 0.17119475, 0.19498...   6975  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_negative = result[0:9]\n",
    "result_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb424cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的列表，用于存储结果的字典\n",
    "negative_result_data = []\n",
    "\n",
    "# 获取所有可能的情感层组合\n",
    "negative_emotion_layers = result_negative[\"class_means\"].tolist()\n",
    "negative_combinations_layers = list(combinations(negative_emotion_layers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12c5428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_combinations_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a126fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个情感层组合\n",
    "for layer1, layer2 in negative_combinations_layers:\n",
    "    # 获取对应的帖子文本向量\n",
    "    vector_layer1 = result_negative[result_negative['class_means'] == layer1]['avg_post_vector'].values[0]\n",
    "    vector_layer2 = result_negative[result_negative['class_means'] == layer2]['avg_post_vector'].values[0]\n",
    "\n",
    "    # 计算情感得分差值\n",
    "    sentiment_difference = layer2 + layer1\n",
    "\n",
    "    # 计算文本相似度\n",
    "    similarity = cosine_similarity([vector_layer1], [vector_layer2])[0][0]\n",
    "\n",
    "    # 将结果添加到结果数据列表中\n",
    "    negative_result_data.append({\n",
    "        \"emotion_layer1\": layer1,\n",
    "        \"emotion_layer2\": layer2,\n",
    "        \"sentiment_difference\": sentiment_difference,\n",
    "        \"text_similarity\": similarity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd428a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_layer1</th>\n",
       "      <th>emotion_layer2</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>text_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-1.773528</td>\n",
       "      <td>0.995212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-1.678190</td>\n",
       "      <td>0.988209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-1.575170</td>\n",
       "      <td>0.982336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-1.479568</td>\n",
       "      <td>0.978165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-1.370923</td>\n",
       "      <td>0.964328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-1.277977</td>\n",
       "      <td>0.958944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-1.181173</td>\n",
       "      <td>0.955292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-1.069216</td>\n",
       "      <td>0.963277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-1.595127</td>\n",
       "      <td>0.998246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-1.492107</td>\n",
       "      <td>0.994759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-1.396505</td>\n",
       "      <td>0.991157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-1.287859</td>\n",
       "      <td>0.981479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-1.194914</td>\n",
       "      <td>0.979729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-1.098110</td>\n",
       "      <td>0.975047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.986153</td>\n",
       "      <td>0.980767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-1.396769</td>\n",
       "      <td>0.998437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-1.301167</td>\n",
       "      <td>0.995859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-1.192522</td>\n",
       "      <td>0.989157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-1.099577</td>\n",
       "      <td>0.989052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-1.002772</td>\n",
       "      <td>0.984495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.890815</td>\n",
       "      <td>0.988592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-1.198147</td>\n",
       "      <td>0.998438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-1.089501</td>\n",
       "      <td>0.995267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.996556</td>\n",
       "      <td>0.994359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.899752</td>\n",
       "      <td>0.991884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.787795</td>\n",
       "      <td>0.994130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.993899</td>\n",
       "      <td>0.997201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.900954</td>\n",
       "      <td>0.995957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.804150</td>\n",
       "      <td>0.993669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.692193</td>\n",
       "      <td>0.996119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.792309</td>\n",
       "      <td>0.998224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.695504</td>\n",
       "      <td>0.998288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.583547</td>\n",
       "      <td>0.998222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.602559</td>\n",
       "      <td>0.997320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.490602</td>\n",
       "      <td>0.997437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.393798</td>\n",
       "      <td>0.997374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion_layer1  emotion_layer2  sentiment_difference  text_similarity\n",
       "0        -0.928296       -0.845232             -1.773528         0.995212\n",
       "1        -0.928296       -0.749895             -1.678190         0.988209\n",
       "2        -0.928296       -0.646874             -1.575170         0.982336\n",
       "3        -0.928296       -0.551272             -1.479568         0.978165\n",
       "4        -0.928296       -0.442627             -1.370923         0.964328\n",
       "5        -0.928296       -0.349682             -1.277977         0.958944\n",
       "6        -0.928296       -0.252877             -1.181173         0.955292\n",
       "7        -0.928296       -0.140920             -1.069216         0.963277\n",
       "8        -0.845232       -0.749895             -1.595127         0.998246\n",
       "9        -0.845232       -0.646874             -1.492107         0.994759\n",
       "10       -0.845232       -0.551272             -1.396505         0.991157\n",
       "11       -0.845232       -0.442627             -1.287859         0.981479\n",
       "12       -0.845232       -0.349682             -1.194914         0.979729\n",
       "13       -0.845232       -0.252877             -1.098110         0.975047\n",
       "14       -0.845232       -0.140920             -0.986153         0.980767\n",
       "15       -0.749895       -0.646874             -1.396769         0.998437\n",
       "16       -0.749895       -0.551272             -1.301167         0.995859\n",
       "17       -0.749895       -0.442627             -1.192522         0.989157\n",
       "18       -0.749895       -0.349682             -1.099577         0.989052\n",
       "19       -0.749895       -0.252877             -1.002772         0.984495\n",
       "20       -0.749895       -0.140920             -0.890815         0.988592\n",
       "21       -0.646874       -0.551272             -1.198147         0.998438\n",
       "22       -0.646874       -0.442627             -1.089501         0.995267\n",
       "23       -0.646874       -0.349682             -0.996556         0.994359\n",
       "24       -0.646874       -0.252877             -0.899752         0.991884\n",
       "25       -0.646874       -0.140920             -0.787795         0.994130\n",
       "26       -0.551272       -0.442627             -0.993899         0.997201\n",
       "27       -0.551272       -0.349682             -0.900954         0.995957\n",
       "28       -0.551272       -0.252877             -0.804150         0.993669\n",
       "29       -0.551272       -0.140920             -0.692193         0.996119\n",
       "30       -0.442627       -0.349682             -0.792309         0.998224\n",
       "31       -0.442627       -0.252877             -0.695504         0.998288\n",
       "32       -0.442627       -0.140920             -0.583547         0.998222\n",
       "33       -0.349682       -0.252877             -0.602559         0.997320\n",
       "34       -0.349682       -0.140920             -0.490602         0.997437\n",
       "35       -0.252877       -0.140920             -0.393798         0.997374"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pd.DataFrame 将结果数据转换为 DataFrame\n",
    "negative_result_df = pd.DataFrame(negative_result_data)\n",
    "\n",
    "# 打印或使用 result_df\n",
    "negative_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2479fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_result_df.to_csv('/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/negative_result_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f47d39",
   "metadata": {},
   "source": [
    "## 积极情感的 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0af2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>[0.05148582, 0.13148741, 0.17426367, 0.2095842...</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.176417</td>\n",
       "      <td>[0.033962816, 0.15324391, 0.18930298, 0.206876...</td>\n",
       "      <td>8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>-0.111372</td>\n",
       "      <td>[0.04170527, 0.17339887, 0.20434564, 0.2057485...</td>\n",
       "      <td>19535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>[0.00036953914, 0.18359077, 0.24117234, 0.2211...</td>\n",
       "      <td>21751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.080733</td>\n",
       "      <td>[0.012572618, 0.18861452, 0.24131083, 0.233405...</td>\n",
       "      <td>31101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>[0.024465693, 0.16275266, 0.2184426, 0.2094585...</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>-0.145374</td>\n",
       "      <td>[0.024239006, 0.14219417, 0.23383643, 0.211597...</td>\n",
       "      <td>16013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>[0.035012137, 0.1352557, 0.21679793, 0.2009265...</td>\n",
       "      <td>13152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>[0.047027096, 0.110957816, 0.20543592, 0.19200...</td>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.049405783, 0.07209749, 0.21523431, 0.195098...</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion Layer  class_means  class_means.1  \\\n",
       "10             10     0.056094      -0.066174   \n",
       "11             11     0.139707      -0.176417   \n",
       "12             12     0.257558      -0.111372   \n",
       "13             13     0.352665      -0.093678   \n",
       "14             14     0.441582       0.080733   \n",
       "15             15     0.554503      -0.198971   \n",
       "16             16     0.647155      -0.145374   \n",
       "17             17     0.745005       0.221816   \n",
       "18             18     0.840652       0.932850   \n",
       "19             19     0.930934       0.162922   \n",
       "\n",
       "                                      avg_post_vector   text  \n",
       "10  [0.05148582, 0.13148741, 0.17426367, 0.2095842...   6696  \n",
       "11  [0.033962816, 0.15324391, 0.18930298, 0.206876...   8824  \n",
       "12  [0.04170527, 0.17339887, 0.20434564, 0.2057485...  19535  \n",
       "13  [0.00036953914, 0.18359077, 0.24117234, 0.2211...  21751  \n",
       "14  [0.012572618, 0.18861452, 0.24131083, 0.233405...  31101  \n",
       "15  [0.024465693, 0.16275266, 0.2184426, 0.2094585...  16965  \n",
       "16  [0.024239006, 0.14219417, 0.23383643, 0.211597...  16013  \n",
       "17  [0.035012137, 0.1352557, 0.21679793, 0.2009265...  13152  \n",
       "18  [0.047027096, 0.110957816, 0.20543592, 0.19200...   8590  \n",
       "19  [0.049405783, 0.07209749, 0.21523431, 0.195098...   2244  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_positive = result[10:20]\n",
    "result_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbae12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的列表，用于存储结果的字典\n",
    "positive_result_data = []\n",
    "\n",
    "# 获取所有可能的情感层组合\n",
    "positive_emotion_layers = result_positive[\"class_means\"].tolist()\n",
    "positive_combinations_layers = list(combinations(positive_emotion_layers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cb2bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_combinations_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "841ddae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个情感层组合\n",
    "for layer1, layer2 in positive_combinations_layers:\n",
    "    # 获取对应的帖子文本向量\n",
    "    vector_layer1 = result_positive[result_positive['class_means'] == layer1]['avg_post_vector'].values[0]\n",
    "    vector_layer2 = result_positive[result_positive['class_means'] == layer2]['avg_post_vector'].values[0]\n",
    "\n",
    "    # 计算情感得分差值\n",
    "    sentiment_difference = layer2 + layer1\n",
    "\n",
    "    # 计算文本相似度\n",
    "    similarity = cosine_similarity([vector_layer1], [vector_layer2])[0][0]\n",
    "\n",
    "    # 将结果添加到结果数据列表中\n",
    "    positive_result_data.append({\n",
    "        \"emotion_layer1\": layer1,\n",
    "        \"emotion_layer2\": layer2,\n",
    "        \"sentiment_difference\": sentiment_difference,\n",
    "        \"text_similarity\": similarity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "88817ad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_layer1</th>\n",
       "      <th>emotion_layer2</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>text_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.195800</td>\n",
       "      <td>0.997913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.313652</td>\n",
       "      <td>0.991913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.408759</td>\n",
       "      <td>0.988802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.497676</td>\n",
       "      <td>0.988790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.610597</td>\n",
       "      <td>0.993632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.703248</td>\n",
       "      <td>0.991612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.801099</td>\n",
       "      <td>0.991182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.896746</td>\n",
       "      <td>0.987071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.987028</td>\n",
       "      <td>0.976177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.397265</td>\n",
       "      <td>0.993428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.492372</td>\n",
       "      <td>0.992084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.581289</td>\n",
       "      <td>0.991251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.694210</td>\n",
       "      <td>0.995547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.993216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.884712</td>\n",
       "      <td>0.992836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.980359</td>\n",
       "      <td>0.988017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.139707</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.070641</td>\n",
       "      <td>0.975401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.610224</td>\n",
       "      <td>0.995921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.699140</td>\n",
       "      <td>0.996192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.812061</td>\n",
       "      <td>0.997494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.904713</td>\n",
       "      <td>0.994987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>1.002564</td>\n",
       "      <td>0.992281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>0.986704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.257558</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.188493</td>\n",
       "      <td>0.973129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.794248</td>\n",
       "      <td>0.997864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.907168</td>\n",
       "      <td>0.997410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>0.996480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>1.097671</td>\n",
       "      <td>0.993656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.193318</td>\n",
       "      <td>0.987746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.352665</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.283600</td>\n",
       "      <td>0.973828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.996085</td>\n",
       "      <td>0.996973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>1.088737</td>\n",
       "      <td>0.995953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>1.186588</td>\n",
       "      <td>0.992649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.282234</td>\n",
       "      <td>0.986552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.372516</td>\n",
       "      <td>0.974481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>1.201657</td>\n",
       "      <td>0.998964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>1.299508</td>\n",
       "      <td>0.997815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.395155</td>\n",
       "      <td>0.993945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.554503</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.485437</td>\n",
       "      <td>0.983438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>1.392160</td>\n",
       "      <td>0.999050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.487807</td>\n",
       "      <td>0.996553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.578089</td>\n",
       "      <td>0.987841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.585658</td>\n",
       "      <td>0.998787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.675940</td>\n",
       "      <td>0.991773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.771587</td>\n",
       "      <td>0.996077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion_layer1  emotion_layer2  sentiment_difference  text_similarity\n",
       "0         0.056094        0.139707              0.195800         0.997913\n",
       "1         0.056094        0.257558              0.313652         0.991913\n",
       "2         0.056094        0.352665              0.408759         0.988802\n",
       "3         0.056094        0.441582              0.497676         0.988790\n",
       "4         0.056094        0.554503              0.610597         0.993632\n",
       "5         0.056094        0.647155              0.703248         0.991612\n",
       "6         0.056094        0.745005              0.801099         0.991182\n",
       "7         0.056094        0.840652              0.896746         0.987071\n",
       "8         0.056094        0.930934              0.987028         0.976177\n",
       "9         0.139707        0.257558              0.397265         0.993428\n",
       "10        0.139707        0.352665              0.492372         0.992084\n",
       "11        0.139707        0.441582              0.581289         0.991251\n",
       "12        0.139707        0.554503              0.694210         0.995547\n",
       "13        0.139707        0.647155              0.786861         0.993216\n",
       "14        0.139707        0.745005              0.884712         0.992836\n",
       "15        0.139707        0.840652              0.980359         0.988017\n",
       "16        0.139707        0.930934              1.070641         0.975401\n",
       "17        0.257558        0.352665              0.610224         0.995921\n",
       "18        0.257558        0.441582              0.699140         0.996192\n",
       "19        0.257558        0.554503              0.812061         0.997494\n",
       "20        0.257558        0.647155              0.904713         0.994987\n",
       "21        0.257558        0.745005              1.002564         0.992281\n",
       "22        0.257558        0.840652              1.098210         0.986704\n",
       "23        0.257558        0.930934              1.188493         0.973129\n",
       "24        0.352665        0.441582              0.794248         0.997864\n",
       "25        0.352665        0.554503              0.907168         0.997410\n",
       "26        0.352665        0.647155              0.999820         0.996480\n",
       "27        0.352665        0.745005              1.097671         0.993656\n",
       "28        0.352665        0.840652              1.193318         0.987746\n",
       "29        0.352665        0.930934              1.283600         0.973828\n",
       "30        0.441582        0.554503              0.996085         0.996973\n",
       "31        0.441582        0.647155              1.088737         0.995953\n",
       "32        0.441582        0.745005              1.186588         0.992649\n",
       "33        0.441582        0.840652              1.282234         0.986552\n",
       "34        0.441582        0.930934              1.372516         0.974481\n",
       "35        0.554503        0.647155              1.201657         0.998964\n",
       "36        0.554503        0.745005              1.299508         0.997815\n",
       "37        0.554503        0.840652              1.395155         0.993945\n",
       "38        0.554503        0.930934              1.485437         0.983438\n",
       "39        0.647155        0.745005              1.392160         0.999050\n",
       "40        0.647155        0.840652              1.487807         0.996553\n",
       "41        0.647155        0.930934              1.578089         0.987841\n",
       "42        0.745005        0.840652              1.585658         0.998787\n",
       "43        0.745005        0.930934              1.675940         0.991773\n",
       "44        0.840652        0.930934              1.771587         0.996077"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pd.DataFrame 将结果数据转换为 DataFrame\n",
    "positive_result_df = pd.DataFrame(positive_result_data)\n",
    "\n",
    "# 打印或使用 result_df\n",
    "positive_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f88be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_result_df.to_csv('/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/positive_result_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b14442",
   "metadata": {},
   "source": [
    "# 计算总的情感强度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1076f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.11759956, -0.01240221, 0.06883255, 0.188099...</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>[0.08206962, 0.018623926, 0.10427251, 0.181156...</td>\n",
       "      <td>4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>[0.06759872, 0.044921823, 0.12548852, 0.187796...</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>[0.07044125, 0.056578968, 0.14015035, 0.193981...</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>[0.054441523, 0.08644522, 0.15405329, 0.203952...</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>[0.05191691, 0.09795757, 0.1707494, 0.20189716...</td>\n",
       "      <td>10187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>[0.02052315, 0.11462396, 0.18370864, 0.1934834...</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>[0.04575353, 0.12028619, 0.1723895, 0.21996947...</td>\n",
       "      <td>11067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>[0.067101896, 0.115399264, 0.17119475, 0.19498...</td>\n",
       "      <td>6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>[-0.015747102, 0.20054203, 0.24620117, 0.23879...</td>\n",
       "      <td>120919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>[0.05148582, 0.13148741, 0.17426367, 0.2095842...</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.176417</td>\n",
       "      <td>[0.033962816, 0.15324391, 0.18930298, 0.206876...</td>\n",
       "      <td>8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>-0.111372</td>\n",
       "      <td>[0.04170527, 0.17339887, 0.20434564, 0.2057485...</td>\n",
       "      <td>19535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>[0.00036953914, 0.18359077, 0.24117234, 0.2211...</td>\n",
       "      <td>21751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.080733</td>\n",
       "      <td>[0.012572618, 0.18861452, 0.24131083, 0.233405...</td>\n",
       "      <td>31101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>[0.024465693, 0.16275266, 0.2184426, 0.2094585...</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>-0.145374</td>\n",
       "      <td>[0.024239006, 0.14219417, 0.23383643, 0.211597...</td>\n",
       "      <td>16013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>[0.035012137, 0.1352557, 0.21679793, 0.2009265...</td>\n",
       "      <td>13152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>[0.047027096, 0.110957816, 0.20543592, 0.19200...</td>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.049405783, 0.07209749, 0.21523431, 0.195098...</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion Layer  class_means  class_means.1  \\\n",
       "0               0    -0.928296      -0.169739   \n",
       "1               1    -0.845232      -0.127592   \n",
       "2               2    -0.749895      -0.110690   \n",
       "3               3    -0.646874      -0.138797   \n",
       "4               4    -0.551272       0.059986   \n",
       "5               5    -0.442627      -0.021977   \n",
       "6               6    -0.349682      -0.165579   \n",
       "7               7    -0.252877      -0.073312   \n",
       "8               8    -0.140920      -0.064764   \n",
       "9               9    -0.002524       0.021858   \n",
       "10             10     0.056094      -0.066174   \n",
       "11             11     0.139707      -0.176417   \n",
       "12             12     0.257558      -0.111372   \n",
       "13             13     0.352665      -0.093678   \n",
       "14             14     0.441582       0.080733   \n",
       "15             15     0.554503      -0.198971   \n",
       "16             16     0.647155      -0.145374   \n",
       "17             17     0.745005       0.221816   \n",
       "18             18     0.840652       0.932850   \n",
       "19             19     0.930934       0.162922   \n",
       "\n",
       "                                      avg_post_vector    text  \n",
       "0   [0.11759956, -0.01240221, 0.06883255, 0.188099...    1491  \n",
       "1   [0.08206962, 0.018623926, 0.10427251, 0.181156...    4639  \n",
       "2   [0.06759872, 0.044921823, 0.12548852, 0.187796...    6246  \n",
       "3   [0.07044125, 0.056578968, 0.14015035, 0.193981...    6614  \n",
       "4   [0.054441523, 0.08644522, 0.15405329, 0.203952...    9290  \n",
       "5   [0.05191691, 0.09795757, 0.1707494, 0.20189716...   10187  \n",
       "6   [0.02052315, 0.11462396, 0.18370864, 0.1934834...    9581  \n",
       "7   [0.04575353, 0.12028619, 0.1723895, 0.21996947...   11067  \n",
       "8   [0.067101896, 0.115399264, 0.17119475, 0.19498...    6975  \n",
       "9   [-0.015747102, 0.20054203, 0.24620117, 0.23879...  120919  \n",
       "10  [0.05148582, 0.13148741, 0.17426367, 0.2095842...    6696  \n",
       "11  [0.033962816, 0.15324391, 0.18930298, 0.206876...    8824  \n",
       "12  [0.04170527, 0.17339887, 0.20434564, 0.2057485...   19535  \n",
       "13  [0.00036953914, 0.18359077, 0.24117234, 0.2211...   21751  \n",
       "14  [0.012572618, 0.18861452, 0.24131083, 0.233405...   31101  \n",
       "15  [0.024465693, 0.16275266, 0.2184426, 0.2094585...   16965  \n",
       "16  [0.024239006, 0.14219417, 0.23383643, 0.211597...   16013  \n",
       "17  [0.035012137, 0.1352557, 0.21679793, 0.2009265...   13152  \n",
       "18  [0.047027096, 0.110957816, 0.20543592, 0.19200...    8590  \n",
       "19  [0.049405783, 0.07209749, 0.21523431, 0.195098...    2244  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_strength = result[0:20]\n",
    "result_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "39e266db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.11759956, -0.01240221, 0.06883255, 0.188099...</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>[0.08206962, 0.018623926, 0.10427251, 0.181156...</td>\n",
       "      <td>4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.749895</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>[0.06759872, 0.044921823, 0.12548852, 0.187796...</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.646874</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>[0.07044125, 0.056578968, 0.14015035, 0.193981...</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.551272</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>[0.054441523, 0.08644522, 0.15405329, 0.203952...</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.442627</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>[0.05191691, 0.09795757, 0.1707494, 0.20189716...</td>\n",
       "      <td>10187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.349682</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>[0.02052315, 0.11462396, 0.18370864, 0.1934834...</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.252877</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>[0.04575353, 0.12028619, 0.1723895, 0.21996947...</td>\n",
       "      <td>11067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.140920</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>[0.067101896, 0.115399264, 0.17119475, 0.19498...</td>\n",
       "      <td>6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>[-0.015747102, 0.20054203, 0.24620117, 0.23879...</td>\n",
       "      <td>120919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>[0.05148582, 0.13148741, 0.17426367, 0.2095842...</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.176417</td>\n",
       "      <td>[0.033962816, 0.15324391, 0.18930298, 0.206876...</td>\n",
       "      <td>8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>-0.111372</td>\n",
       "      <td>[0.04170527, 0.17339887, 0.20434564, 0.2057485...</td>\n",
       "      <td>19535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>[0.00036953914, 0.18359077, 0.24117234, 0.2211...</td>\n",
       "      <td>21751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.080733</td>\n",
       "      <td>[0.012572618, 0.18861452, 0.24131083, 0.233405...</td>\n",
       "      <td>31101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>[0.024465693, 0.16275266, 0.2184426, 0.2094585...</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>-0.145374</td>\n",
       "      <td>[0.024239006, 0.14219417, 0.23383643, 0.211597...</td>\n",
       "      <td>16013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>[0.035012137, 0.1352557, 0.21679793, 0.2009265...</td>\n",
       "      <td>13152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>[0.047027096, 0.110957816, 0.20543592, 0.19200...</td>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.049405783, 0.07209749, 0.21523431, 0.195098...</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion Layer  class_means  class_means.1  \\\n",
       "0               0     0.928296      -0.169739   \n",
       "1               1     0.845232      -0.127592   \n",
       "2               2     0.749895      -0.110690   \n",
       "3               3     0.646874      -0.138797   \n",
       "4               4     0.551272       0.059986   \n",
       "5               5     0.442627      -0.021977   \n",
       "6               6     0.349682      -0.165579   \n",
       "7               7     0.252877      -0.073312   \n",
       "8               8     0.140920      -0.064764   \n",
       "9               9     0.002524       0.021858   \n",
       "10             10     0.056094      -0.066174   \n",
       "11             11     0.139707      -0.176417   \n",
       "12             12     0.257558      -0.111372   \n",
       "13             13     0.352665      -0.093678   \n",
       "14             14     0.441582       0.080733   \n",
       "15             15     0.554503      -0.198971   \n",
       "16             16     0.647155      -0.145374   \n",
       "17             17     0.745005       0.221816   \n",
       "18             18     0.840652       0.932850   \n",
       "19             19     0.930934       0.162922   \n",
       "\n",
       "                                      avg_post_vector    text  \n",
       "0   [0.11759956, -0.01240221, 0.06883255, 0.188099...    1491  \n",
       "1   [0.08206962, 0.018623926, 0.10427251, 0.181156...    4639  \n",
       "2   [0.06759872, 0.044921823, 0.12548852, 0.187796...    6246  \n",
       "3   [0.07044125, 0.056578968, 0.14015035, 0.193981...    6614  \n",
       "4   [0.054441523, 0.08644522, 0.15405329, 0.203952...    9290  \n",
       "5   [0.05191691, 0.09795757, 0.1707494, 0.20189716...   10187  \n",
       "6   [0.02052315, 0.11462396, 0.18370864, 0.1934834...    9581  \n",
       "7   [0.04575353, 0.12028619, 0.1723895, 0.21996947...   11067  \n",
       "8   [0.067101896, 0.115399264, 0.17119475, 0.19498...    6975  \n",
       "9   [-0.015747102, 0.20054203, 0.24620117, 0.23879...  120919  \n",
       "10  [0.05148582, 0.13148741, 0.17426367, 0.2095842...    6696  \n",
       "11  [0.033962816, 0.15324391, 0.18930298, 0.206876...    8824  \n",
       "12  [0.04170527, 0.17339887, 0.20434564, 0.2057485...   19535  \n",
       "13  [0.00036953914, 0.18359077, 0.24117234, 0.2211...   21751  \n",
       "14  [0.012572618, 0.18861452, 0.24131083, 0.233405...   31101  \n",
       "15  [0.024465693, 0.16275266, 0.2184426, 0.2094585...   16965  \n",
       "16  [0.024239006, 0.14219417, 0.23383643, 0.211597...   16013  \n",
       "17  [0.035012137, 0.1352557, 0.21679793, 0.2009265...   13152  \n",
       "18  [0.047027096, 0.110957816, 0.20543592, 0.19200...    8590  \n",
       "19  [0.049405783, 0.07209749, 0.21523431, 0.195098...    2244  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_strength[\"class_means\"] = result_strength[\"class_means\"].abs()\n",
    "result_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c9816f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的列表，用于存储结果的字典\n",
    "result_strength_data = []\n",
    "\n",
    "# 获取所有可能的情感层组合\n",
    "strength_emotion_layers = result_strength[\"class_means\"].tolist()\n",
    "strength_combinations_layers = list(combinations(strength_emotion_layers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9209d3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strength_combinations_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "372e3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个情感层组合\n",
    "for layer1, layer2 in strength_combinations_layers:\n",
    "    # 获取对应的帖子文本向量\n",
    "    vector_layer1 = result_strength[result_strength['class_means'] == layer1]['avg_post_vector'].values[0]\n",
    "    vector_layer2 = result_strength[result_strength['class_means'] == layer2]['avg_post_vector'].values[0]\n",
    "\n",
    "    # 计算情感得分差值\n",
    "    sentiment_difference = layer2 + layer1\n",
    "\n",
    "    # 计算文本相似度\n",
    "    similarity = cosine_similarity([vector_layer1], [vector_layer2])[0][0]\n",
    "\n",
    "    # 将结果添加到结果数据列表中\n",
    "    result_strength_data.append({\n",
    "        \"emotion_layer1\": layer1,\n",
    "        \"emotion_layer2\": layer2,\n",
    "        \"sentiment_difference\": sentiment_difference,\n",
    "        \"text_similarity\": similarity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92565006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_layer1</th>\n",
       "      <th>emotion_layer2</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>text_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.845232</td>\n",
       "      <td>1.773528</td>\n",
       "      <td>0.995212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.749895</td>\n",
       "      <td>1.678190</td>\n",
       "      <td>0.988209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.646874</td>\n",
       "      <td>1.575170</td>\n",
       "      <td>0.982336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.551272</td>\n",
       "      <td>1.479568</td>\n",
       "      <td>0.978165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.442627</td>\n",
       "      <td>1.370923</td>\n",
       "      <td>0.964328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.487807</td>\n",
       "      <td>0.996553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.578089</td>\n",
       "      <td>0.987841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.585658</td>\n",
       "      <td>0.998787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.675940</td>\n",
       "      <td>0.991773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.771587</td>\n",
       "      <td>0.996077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion_layer1  emotion_layer2  sentiment_difference  text_similarity\n",
       "0          0.928296        0.845232              1.773528         0.995212\n",
       "1          0.928296        0.749895              1.678190         0.988209\n",
       "2          0.928296        0.646874              1.575170         0.982336\n",
       "3          0.928296        0.551272              1.479568         0.978165\n",
       "4          0.928296        0.442627              1.370923         0.964328\n",
       "..              ...             ...                   ...              ...\n",
       "185        0.647155        0.840652              1.487807         0.996553\n",
       "186        0.647155        0.930934              1.578089         0.987841\n",
       "187        0.745005        0.840652              1.585658         0.998787\n",
       "188        0.745005        0.930934              1.675940         0.991773\n",
       "189        0.840652        0.930934              1.771587         0.996077\n",
       "\n",
       "[190 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pd.DataFrame 将结果数据转换为 DataFrame\n",
    "strength_result_df = pd.DataFrame(result_strength_data)\n",
    "\n",
    "# 打印或使用 result_df\n",
    "strength_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17c4b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "strength_result_df.to_csv('/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/strength_result_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e36ab5",
   "metadata": {},
   "source": [
    "# 计算单极化程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb69f2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.11759956, -0.01240221, 0.06883255, 0.188099...</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>[0.08206962, 0.018623926, 0.10427251, 0.181156...</td>\n",
       "      <td>4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>[0.06759872, 0.044921823, 0.12548852, 0.187796...</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>[0.07044125, 0.056578968, 0.14015035, 0.193981...</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>[0.054441523, 0.08644522, 0.15405329, 0.203952...</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>[0.05191691, 0.09795757, 0.1707494, 0.20189716...</td>\n",
       "      <td>10187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>[0.02052315, 0.11462396, 0.18370864, 0.1934834...</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>[0.04575353, 0.12028619, 0.1723895, 0.21996947...</td>\n",
       "      <td>11067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>[0.067101896, 0.115399264, 0.17119475, 0.19498...</td>\n",
       "      <td>6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>[-0.015747102, 0.20054203, 0.24620117, 0.23879...</td>\n",
       "      <td>120919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>[0.05148582, 0.13148741, 0.17426367, 0.2095842...</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.176417</td>\n",
       "      <td>[0.033962816, 0.15324391, 0.18930298, 0.206876...</td>\n",
       "      <td>8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>-0.111372</td>\n",
       "      <td>[0.04170527, 0.17339887, 0.20434564, 0.2057485...</td>\n",
       "      <td>19535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>[0.00036953914, 0.18359077, 0.24117234, 0.2211...</td>\n",
       "      <td>21751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.080733</td>\n",
       "      <td>[0.012572618, 0.18861452, 0.24131083, 0.233405...</td>\n",
       "      <td>31101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>[0.024465693, 0.16275266, 0.2184426, 0.2094585...</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>-0.145374</td>\n",
       "      <td>[0.024239006, 0.14219417, 0.23383643, 0.211597...</td>\n",
       "      <td>16013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>[0.035012137, 0.1352557, 0.21679793, 0.2009265...</td>\n",
       "      <td>13152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>[0.047027096, 0.110957816, 0.20543592, 0.19200...</td>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.049405783, 0.07209749, 0.21523431, 0.195098...</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion Layer  class_means  class_means.1  \\\n",
       "0               0    -0.928296      -0.169739   \n",
       "1               1    -0.845232      -0.127592   \n",
       "2               2    -0.749895      -0.110690   \n",
       "3               3    -0.646874      -0.138797   \n",
       "4               4    -0.551272       0.059986   \n",
       "5               5    -0.442627      -0.021977   \n",
       "6               6    -0.349682      -0.165579   \n",
       "7               7    -0.252877      -0.073312   \n",
       "8               8    -0.140920      -0.064764   \n",
       "9               9    -0.002524       0.021858   \n",
       "10             10     0.056094      -0.066174   \n",
       "11             11     0.139707      -0.176417   \n",
       "12             12     0.257558      -0.111372   \n",
       "13             13     0.352665      -0.093678   \n",
       "14             14     0.441582       0.080733   \n",
       "15             15     0.554503      -0.198971   \n",
       "16             16     0.647155      -0.145374   \n",
       "17             17     0.745005       0.221816   \n",
       "18             18     0.840652       0.932850   \n",
       "19             19     0.930934       0.162922   \n",
       "\n",
       "                                      avg_post_vector    text  \n",
       "0   [0.11759956, -0.01240221, 0.06883255, 0.188099...    1491  \n",
       "1   [0.08206962, 0.018623926, 0.10427251, 0.181156...    4639  \n",
       "2   [0.06759872, 0.044921823, 0.12548852, 0.187796...    6246  \n",
       "3   [0.07044125, 0.056578968, 0.14015035, 0.193981...    6614  \n",
       "4   [0.054441523, 0.08644522, 0.15405329, 0.203952...    9290  \n",
       "5   [0.05191691, 0.09795757, 0.1707494, 0.20189716...   10187  \n",
       "6   [0.02052315, 0.11462396, 0.18370864, 0.1934834...    9581  \n",
       "7   [0.04575353, 0.12028619, 0.1723895, 0.21996947...   11067  \n",
       "8   [0.067101896, 0.115399264, 0.17119475, 0.19498...    6975  \n",
       "9   [-0.015747102, 0.20054203, 0.24620117, 0.23879...  120919  \n",
       "10  [0.05148582, 0.13148741, 0.17426367, 0.2095842...    6696  \n",
       "11  [0.033962816, 0.15324391, 0.18930298, 0.206876...    8824  \n",
       "12  [0.04170527, 0.17339887, 0.20434564, 0.2057485...   19535  \n",
       "13  [0.00036953914, 0.18359077, 0.24117234, 0.2211...   21751  \n",
       "14  [0.012572618, 0.18861452, 0.24131083, 0.233405...   31101  \n",
       "15  [0.024465693, 0.16275266, 0.2184426, 0.2094585...   16965  \n",
       "16  [0.024239006, 0.14219417, 0.23383643, 0.211597...   16013  \n",
       "17  [0.035012137, 0.1352557, 0.21679793, 0.2009265...   13152  \n",
       "18  [0.047027096, 0.110957816, 0.20543592, 0.19200...    8590  \n",
       "19  [0.049405783, 0.07209749, 0.21523431, 0.195098...    2244  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_single_polar = result[0:20]\n",
    "result_single_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "436b5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的列表，用于存储结果的字典\n",
    "result_sinpolar_data = []\n",
    "\n",
    "# 获取所有可能的情感层组合\n",
    "sinpolar_emotion_layers = result_single_polar[\"class_means\"].tolist()\n",
    "sinpolar_combinations_layers = list(combinations(sinpolar_emotion_layers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da96b68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sinpolar_combinations_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8edb2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个情感层组合\n",
    "for layer1, layer2 in sinpolar_combinations_layers:\n",
    "    # 获取对应的帖子文本向量\n",
    "    vector_layer1 = result_single_polar[result_single_polar['class_means'] == layer1]['avg_post_vector'].values[0]\n",
    "    vector_layer2 = result_single_polar[result_single_polar['class_means'] == layer2]['avg_post_vector'].values[0]\n",
    "\n",
    "    # 计算情感得分和\n",
    "    sentiment_sum = layer2 + layer1\n",
    "\n",
    "    # 计算文本相似度\n",
    "    similarity = cosine_similarity([vector_layer1], [vector_layer2])[0][0]\n",
    "\n",
    "    # 将结果添加到结果数据列表中\n",
    "    result_sinpolar_data.append({\n",
    "        \"emotion_layer1\": layer1,\n",
    "        \"emotion_layer2\": layer2,\n",
    "        \"sentiment_difference\": sentiment_sum,\n",
    "        \"text_similarity\": similarity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3235d0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_layer1</th>\n",
       "      <th>emotion_layer2</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>text_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-1.773528</td>\n",
       "      <td>0.995212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-1.678190</td>\n",
       "      <td>0.988209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-1.575170</td>\n",
       "      <td>0.982336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>-1.479568</td>\n",
       "      <td>0.978165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-1.370923</td>\n",
       "      <td>0.964328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.487807</td>\n",
       "      <td>0.996553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.647155</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.578089</td>\n",
       "      <td>0.987841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>1.585658</td>\n",
       "      <td>0.998787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.675940</td>\n",
       "      <td>0.991773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>1.771587</td>\n",
       "      <td>0.996077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion_layer1  emotion_layer2  sentiment_difference  text_similarity\n",
       "0         -0.928296       -0.845232             -1.773528         0.995212\n",
       "1         -0.928296       -0.749895             -1.678190         0.988209\n",
       "2         -0.928296       -0.646874             -1.575170         0.982336\n",
       "3         -0.928296       -0.551272             -1.479568         0.978165\n",
       "4         -0.928296       -0.442627             -1.370923         0.964328\n",
       "..              ...             ...                   ...              ...\n",
       "185        0.647155        0.840652              1.487807         0.996553\n",
       "186        0.647155        0.930934              1.578089         0.987841\n",
       "187        0.745005        0.840652              1.585658         0.998787\n",
       "188        0.745005        0.930934              1.675940         0.991773\n",
       "189        0.840652        0.930934              1.771587         0.996077\n",
       "\n",
       "[190 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pd.DataFrame 将结果数据转换为 DataFrame\n",
    "single_polar_result_df = pd.DataFrame(result_sinpolar_data)\n",
    "\n",
    "# 打印或使用 result_df\n",
    "single_polar_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04a5d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_polar_result_df.to_csv('/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/single_polar_result_df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cdc198",
   "metadata": {},
   "source": [
    "# 计算热度（流行度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccc26ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion Layer</th>\n",
       "      <th>class_means</th>\n",
       "      <th>class_means.1</th>\n",
       "      <th>avg_post_vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.928296</td>\n",
       "      <td>-0.169739</td>\n",
       "      <td>[0.11759956, -0.01240221, 0.06883255, 0.188099...</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.845232</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>[0.08206962, 0.018623926, 0.10427251, 0.181156...</td>\n",
       "      <td>4639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.749895</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>[0.06759872, 0.044921823, 0.12548852, 0.187796...</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.646874</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>[0.07044125, 0.056578968, 0.14015035, 0.193981...</td>\n",
       "      <td>6614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.551272</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>[0.054441523, 0.08644522, 0.15405329, 0.203952...</td>\n",
       "      <td>9290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.442627</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>[0.05191691, 0.09795757, 0.1707494, 0.20189716...</td>\n",
       "      <td>10187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.349682</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>[0.02052315, 0.11462396, 0.18370864, 0.1934834...</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.252877</td>\n",
       "      <td>-0.073312</td>\n",
       "      <td>[0.04575353, 0.12028619, 0.1723895, 0.21996947...</td>\n",
       "      <td>11067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.140920</td>\n",
       "      <td>-0.064764</td>\n",
       "      <td>[0.067101896, 0.115399264, 0.17119475, 0.19498...</td>\n",
       "      <td>6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>[-0.015747102, 0.20054203, 0.24620117, 0.23879...</td>\n",
       "      <td>120919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>-0.066174</td>\n",
       "      <td>[0.05148582, 0.13148741, 0.17426367, 0.2095842...</td>\n",
       "      <td>6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.139707</td>\n",
       "      <td>-0.176417</td>\n",
       "      <td>[0.033962816, 0.15324391, 0.18930298, 0.206876...</td>\n",
       "      <td>8824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.257558</td>\n",
       "      <td>-0.111372</td>\n",
       "      <td>[0.04170527, 0.17339887, 0.20434564, 0.2057485...</td>\n",
       "      <td>19535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.352665</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>[0.00036953914, 0.18359077, 0.24117234, 0.2211...</td>\n",
       "      <td>21751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.441582</td>\n",
       "      <td>0.080733</td>\n",
       "      <td>[0.012572618, 0.18861452, 0.24131083, 0.233405...</td>\n",
       "      <td>31101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.554503</td>\n",
       "      <td>-0.198971</td>\n",
       "      <td>[0.024465693, 0.16275266, 0.2184426, 0.2094585...</td>\n",
       "      <td>16965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.647155</td>\n",
       "      <td>-0.145374</td>\n",
       "      <td>[0.024239006, 0.14219417, 0.23383643, 0.211597...</td>\n",
       "      <td>16013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.745005</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>[0.035012137, 0.1352557, 0.21679793, 0.2009265...</td>\n",
       "      <td>13152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.840652</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>[0.047027096, 0.110957816, 0.20543592, 0.19200...</td>\n",
       "      <td>8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.930934</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>[0.049405783, 0.07209749, 0.21523431, 0.195098...</td>\n",
       "      <td>2244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion Layer  class_means  class_means.1  \\\n",
       "0               0    -0.928296      -0.169739   \n",
       "1               1    -0.845232      -0.127592   \n",
       "2               2    -0.749895      -0.110690   \n",
       "3               3    -0.646874      -0.138797   \n",
       "4               4    -0.551272       0.059986   \n",
       "5               5    -0.442627      -0.021977   \n",
       "6               6    -0.349682      -0.165579   \n",
       "7               7    -0.252877      -0.073312   \n",
       "8               8    -0.140920      -0.064764   \n",
       "9               9    -0.002524       0.021858   \n",
       "10             10     0.056094      -0.066174   \n",
       "11             11     0.139707      -0.176417   \n",
       "12             12     0.257558      -0.111372   \n",
       "13             13     0.352665      -0.093678   \n",
       "14             14     0.441582       0.080733   \n",
       "15             15     0.554503      -0.198971   \n",
       "16             16     0.647155      -0.145374   \n",
       "17             17     0.745005       0.221816   \n",
       "18             18     0.840652       0.932850   \n",
       "19             19     0.930934       0.162922   \n",
       "\n",
       "                                      avg_post_vector    text  \n",
       "0   [0.11759956, -0.01240221, 0.06883255, 0.188099...    1491  \n",
       "1   [0.08206962, 0.018623926, 0.10427251, 0.181156...    4639  \n",
       "2   [0.06759872, 0.044921823, 0.12548852, 0.187796...    6246  \n",
       "3   [0.07044125, 0.056578968, 0.14015035, 0.193981...    6614  \n",
       "4   [0.054441523, 0.08644522, 0.15405329, 0.203952...    9290  \n",
       "5   [0.05191691, 0.09795757, 0.1707494, 0.20189716...   10187  \n",
       "6   [0.02052315, 0.11462396, 0.18370864, 0.1934834...    9581  \n",
       "7   [0.04575353, 0.12028619, 0.1723895, 0.21996947...   11067  \n",
       "8   [0.067101896, 0.115399264, 0.17119475, 0.19498...    6975  \n",
       "9   [-0.015747102, 0.20054203, 0.24620117, 0.23879...  120919  \n",
       "10  [0.05148582, 0.13148741, 0.17426367, 0.2095842...    6696  \n",
       "11  [0.033962816, 0.15324391, 0.18930298, 0.206876...    8824  \n",
       "12  [0.04170527, 0.17339887, 0.20434564, 0.2057485...   19535  \n",
       "13  [0.00036953914, 0.18359077, 0.24117234, 0.2211...   21751  \n",
       "14  [0.012572618, 0.18861452, 0.24131083, 0.233405...   31101  \n",
       "15  [0.024465693, 0.16275266, 0.2184426, 0.2094585...   16965  \n",
       "16  [0.024239006, 0.14219417, 0.23383643, 0.211597...   16013  \n",
       "17  [0.035012137, 0.1352557, 0.21679793, 0.2009265...   13152  \n",
       "18  [0.047027096, 0.110957816, 0.20543592, 0.19200...    8590  \n",
       "19  [0.049405783, 0.07209749, 0.21523431, 0.195098...    2244  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_popular = result[0:20]\n",
    "result_popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a88bc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空的列表，用于存储结果的字典\n",
    "result_popular_data = []\n",
    "\n",
    "# 获取所有可能的情感层组合\n",
    "popular_emotion_layers = result_popular[\"class_means.1\"].tolist()\n",
    "popular_combinations_layers = list(combinations(popular_emotion_layers, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc332f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(popular_combinations_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "593db8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个情感层组合\n",
    "for layer1, layer2 in popular_combinations_layers:\n",
    "    # 获取对应的帖子文本向量\n",
    "    vector_layer1 = result_popular[result_popular['class_means.1'] == layer1]['avg_post_vector'].values[0]\n",
    "    vector_layer2 = result_popular[result_popular['class_means.1'] == layer2]['avg_post_vector'].values[0]\n",
    "\n",
    "    # 计算流行度之和\n",
    "    sentiment_sum = layer2 + layer1\n",
    "\n",
    "    # 计算文本相似度\n",
    "    similarity = cosine_similarity([vector_layer1], [vector_layer2])[0][0]\n",
    "\n",
    "    # 将结果添加到结果数据列表中\n",
    "    result_popular_data.append({\n",
    "        \"emotion_layer1\": layer1,\n",
    "        \"emotion_layer2\": layer2,\n",
    "        \"popular\": sentiment_sum,\n",
    "        \"text_similarity\": similarity\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53dd08cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_layer1</th>\n",
       "      <th>emotion_layer2</th>\n",
       "      <th>popular</th>\n",
       "      <th>text_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.169739</td>\n",
       "      <td>-0.127592</td>\n",
       "      <td>-0.297331</td>\n",
       "      <td>0.995212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.169739</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>-0.280429</td>\n",
       "      <td>0.988209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.169739</td>\n",
       "      <td>-0.138797</td>\n",
       "      <td>-0.308536</td>\n",
       "      <td>0.982336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.169739</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>-0.109753</td>\n",
       "      <td>0.978165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.169739</td>\n",
       "      <td>-0.021977</td>\n",
       "      <td>-0.191716</td>\n",
       "      <td>0.964328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-0.145374</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>0.787476</td>\n",
       "      <td>0.996553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.145374</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.987841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.221816</td>\n",
       "      <td>0.932850</td>\n",
       "      <td>1.154666</td>\n",
       "      <td>0.998787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.221816</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>0.384738</td>\n",
       "      <td>0.991773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.932850</td>\n",
       "      <td>0.162922</td>\n",
       "      <td>1.095772</td>\n",
       "      <td>0.996077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion_layer1  emotion_layer2   popular  text_similarity\n",
       "0         -0.169739       -0.127592 -0.297331         0.995212\n",
       "1         -0.169739       -0.110690 -0.280429         0.988209\n",
       "2         -0.169739       -0.138797 -0.308536         0.982336\n",
       "3         -0.169739        0.059986 -0.109753         0.978165\n",
       "4         -0.169739       -0.021977 -0.191716         0.964328\n",
       "..              ...             ...       ...              ...\n",
       "185       -0.145374        0.932850  0.787476         0.996553\n",
       "186       -0.145374        0.162922  0.017548         0.987841\n",
       "187        0.221816        0.932850  1.154666         0.998787\n",
       "188        0.221816        0.162922  0.384738         0.991773\n",
       "189        0.932850        0.162922  1.095772         0.996077\n",
       "\n",
       "[190 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 pd.DataFrame 将结果数据转换为 DataFrame\n",
    "popular_result_df = pd.DataFrame(result_popular_data)\n",
    "\n",
    "# 打印或使用 result_df\n",
    "popular_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7481f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_result_df.to_csv('/Users/shiwei/Desktop/研究论文/一带一路ERGM数据分析/popular_result_df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9edd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091295a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427f551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a12171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83d290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
